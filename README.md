# NaiveGAflux

[![Build Status](https://travis-ci.com/DrChainsaw/NaiveGAflux.jl.svg?branch=master)](https://travis-ci.com/DrChainsaw/NaiveGAflux.jl)
[![Build Status](https://ci.appveyor.com/api/projects/status/github/DrChainsaw/NaiveGAflux.jl?svg=true)](https://ci.appveyor.com/project/DrChainsaw/NaiveGAflux-jl)
[![Codecov](https://codecov.io/gh/DrChainsaw/NaiveGAflux.jl/branch/master/graph/badge.svg)](https://codecov.io/gh/DrChainsaw/NaiveGAflux.jl)

Neural architecture search for [Flux](https://github.com/FluxML/Flux.jl) through a genetic algorithm.

A marketing person might describe it as "practical proxyless NAS using an unrestricted search space".

The more honest purpose is to serve as a pipe cleaner and example for [NaiveNASflux](https://github.com/DrChainsaw/NaiveNASflux.jl) which is doing most of the heavy lifting.

## Basic Usage

```julia
Pkg.add("https://github.com/DrChainsaw/NaiveGAflux.jl")
```

Package is in development. Not ready for use!

### Search Spaces

The search space is the set of possible architectures which the search policy will look for candidates in. Search spaces are constructed from simple components which gives a lot of flexibility.

Lets start with the most simple search space, a `ParSpace`:

```julia
# Set seed of default random number generator for reproduceable results
using NaiveGAflux, Random
Random.seed!(NaiveGAflux.rng_default, 123)

ps1d = ParSpace([2,4,6,10])

# Draw from the search space
@test ps1d() == 2
@test ps1d() == 6

# Possible to supply another rng than the default one
@test ps1d(MersenneTwister(0)) == 2

# Can be of any dimension and type
ps2d = ParSpace(["1","2","3"], ["4","5","6","7"])

@test typeof(ps1d) == ParSpace{1, Int64}
@test typeof(ps2d) == ParSpace{2, String}

@test ps2d() == ("3", "6")
```

Lets have a look at an example of a search space for convolutional layers:

```julia
Random.seed!(NaiveGAflux.rng_default, 1)

outsizes = 4:32
kernelsizes = 3:9
cs = ConvSpace2D(BaseLayerSpace(outsizes, [relu, elu, selu]), kernelsizes)

@test typeof(cs) == ConvSpace{2}

inputsize = 16
convlayer = cs(inputsize)

@test string(convlayer) == "Conv((5, 4), 16=>18, NNlib.elu)"
```

Lastly, lets look at how to construct a search space for ResNeXt like models:

```julia
Random.seed!(NaiveGAflux.rng_default, 666)

# VertexSpace creates a MutableVertex of layers generated by the wrapped search space
cs = VertexSpace(ConvSpace2D(BaseLayerSpace(8:256, [identity, relu, elu]), 3:5))
bs = VertexSpace(BatchNormSpace([identity, relu]))

# Block of conv->bn and bn-conv respectively.
# Need to make sure there is always at least one SizeAbsorb layer to make fork and res below play nice
csbs = ListArchSpace(cs ,bs)
bscs = ListArchSpace(bs, cs)

# Randomly generate a conv-block:
cblock = ArchSpace(ParSpace1D(cs, csbs, bscs))

# Generate between 1 and 5 layers from csbs
rep = RepeatArchSpace(cblock, 1:5)

# Generate between 2 and 4 parallel paths joined by concatenation (inception like-blocks) from rep
fork = ForkArchSpace(rep, 2:4)

# Generate a residual connection around what is generated by rep
res = ResidualArchSpace(rep)

# ... and a residual fork
resfork = ResidualArchSpace(fork)

# Pick one of the above randomly...
repforkres = ArchSpace(ParSpace1D(rep, fork, res, resfork))

# ...1 to 3 times
blocks = RepeatArchSpace(repforkres, 1:3)

# End each block with subsamping through maxpooling
ms = VertexSpace(MaxPoolSpace(PoolSpace2D([2])))
reduction = ListArchSpace(blocks, ms)

# And lets do 2 to 4 reductions
featureextract = RepeatArchSpace(reduction, 2:4)

# Add 1 to 3 dense layers as outputs
dense = VertexSpace(DenseSpace(BaseLayerSpace(16:512, [relu, selu])))
drep = RepeatArchSpace(dense, 0:2)
# Last layer has fixed output size depending on number of labels
dout=VertexSpace(DenseSpace(BaseLayerSpace(10, identity)))
output = ListArchSpace(drep, dout)

# Aaaand lets glue it together: Feature extracting conv+bn layers -> global pooling -> dense layers
archspace = ListArchSpace(featureextract, GpVertex2D(), output)

# Input is 3 channel image
inputshape = inputvertex("input", 3, FluxConv{2}())

# Sample one architecture from the search space
graph1 = CompGraph(inputshape, archspace(inputshape))
@test nv(graph1) == 123

# And one more...
graph2 = CompGraph(inputshape, archspace(inputshape))
@test nv(graph2) == 75
```

### Mutation

TBD...
