var documenterSearchIndex = {"docs":
[{"location":"reference/crossover/#CrossoverOperationsAPI","page":"Crossover Operations","title":"Crossover Operations","text":"","category":"section"},{"location":"reference/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"tip: Tip!\nMost Wrapping Mutation Operations work for crossover too!","category":"page"},{"location":"reference/crossover/#Core-Vertex-Crossover-Operations","page":"Crossover Operations","title":"Core Vertex Crossover Operations","text":"","category":"section"},{"location":"reference/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"VertexCrossover\nCrossoverSwap","category":"page"},{"location":"reference/crossover/#NaiveGAflux.VertexCrossover","page":"Crossover Operations","title":"NaiveGAflux.VertexCrossover","text":"VertexCrossover{S, PF, CF}\nVertexCrossover(crossover ;selection=FilterMutationAllowed(), pairgen=default_pairgen)\nVertexCrossover(crossover, deviation::Number; selection=FilterMutationAllowed())\n\nApplies crossover to each pair of selected vertices from two CompGraphs.\n\nVertices to select from the first graph is determined by selection (default FilterMutationAllowed) while pairgen  (default default_pairgen) determines how to pair the selected vertices with vertices in the second graph.\n\nThe default pairing function will try to pair vertices which have similar relative topologial order within their graphs.  For instance, if the first graph has 5 vertices and the second has 10, it will pair vertex 2 from the first graph with vertex 4 from the second (assuming they are of compatible type). The parameter deviation can be used to inject noise in this process so that the pairing will randomly deviate where the magnitude of deviation sets how much and how often.\n\nSee also crossover.\n\n\n\n\n\n","category":"type"},{"location":"reference/crossover/#NaiveGAflux.CrossoverSwap","page":"Crossover Operations","title":"NaiveGAflux.CrossoverSwap","text":"CrossoverSwap{F1, F2, F3, S} <: AbstractCrossover{<:AbstractVertex}\nCrossoverSwap(pairgen, mergefun, strategy, selection)\nCrossoverSwap(;pairgen=default_inputs_pairgen, mergefun=default_mergefun, strategy=default_crossoverswap_strategy, selection=FilterMutationAllowed())\nCrossoverSwap(deviation::Number; mergefun=default_mergefun, strategy=default_crossoverswap_strategy, selection=FilterMutationAllowed())\n\nSwap out a part of one graph with a part of another graph, making sure that the graphs do not become connected in the process.\n\nMore concretely, swaps a set of consecutive vertices vs1 set of consecutive vertices vs2 returning the swapped v1 and v2 respectively if successful or v1 and v2 if not.\n\nThe last vertex in vs1 is v1 and the last vertex of vs2 is v2. The other members of vs1 and vs2 are determined  by pairgen (default default_inputs_pairgen) and selection (default FilterMutationAllowed).\n\nIf a vertex v is not capable of having multiple inputs (determined by singleinput(v) == true), vm = mergefun(vi) where  vi is the input to v will be used instead of v and v will be added as the output of vm if necessary.\n\nSee also crossoverswap.\n\nNote: High likelyhood of large accuracy degradation after applying this mutation.\n\n\n\n\n\n","category":"type"},{"location":"reference/crossover/#Core-Optimizer-Crossover-Operations","page":"Crossover Operations","title":"Core Optimizer Crossover Operations","text":"","category":"section"},{"location":"reference/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"OptimizerCrossover\nLearningRateCrossover","category":"page"},{"location":"reference/crossover/#NaiveGAflux.OptimizerCrossover","page":"Crossover Operations","title":"NaiveGAflux.OptimizerCrossover","text":"OptimizerCrossover{C} <: AbstractCrossover{FluxOptimizer}\nOptimizerCrossover()\nOptimizerCrossover(crossover)\n\nApply crossover between optimizers.\n\nType of crossover is determined by crossover (default optimizerswap) which when given a a tuple of two optimizers will return the result of the crossover operation as a tuple of optimizers.\n\nDesigned to be composable with most utility AbstractMutations as well as with itself. For instance, the following seemingly odd construct will swap components of a Flux.Optimiser with a probability of 0.2 per component:\n\nOptimizerCrossover(MutationProbability(OptimizerCrossover(), 0.2))\n\nCompare with the following which either swaps all components or none:\n\nMutationProbability(OptimizerCrossover(), 0.2)\n\n\n\n\n\n","category":"type"},{"location":"reference/crossover/#NaiveGAflux.LearningRateCrossover","page":"Crossover Operations","title":"NaiveGAflux.LearningRateCrossover","text":"LearningRateCrossover()\n\nReturn an OptimizerCrossover which will swap learning rates between optimizers but not change anything else.\n\nDoes not do anything if any of the optimizers don't have a learning rate (e.g. WeightDecay).\n\n\n\n\n\n","category":"function"},{"location":"reference/crossover/#Functions","page":"Crossover Operations","title":"Functions","text":"","category":"section"},{"location":"reference/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"NaiveGAflux.crossover\nNaiveGAflux.crossoverswap\nNaiveGAflux.crossoverswap!\nNaiveGAflux.default_pairgen\nNaiveGAflux.default_inputs_pairgen","category":"page"},{"location":"reference/crossover/#NaiveGAflux.crossover","page":"Crossover Operations","title":"NaiveGAflux.crossover","text":"crossover(g1::CompGraph, g2::CompGraph; selection=FilterMutationAllowed(), pairgen=default_pairgen, crossoverfun=crossoverswap)\n\nPerform crossover between g1 and g2 and return the two children g1' and g2'.\n\nHow the crossover is performed depends on pairgen and crossoverfun as well as selection.\n\nselection is used to filter out at which vertices the crossoverpoints may be.\n\npairgen return indices of the potential crossover points to use out of the allowed crossover points. New crossover points will be drawn from pairgen until it returns nothing.\n\ncrossoverfun return the result of the crossover which may be same as inputs depending on implementation.\n\n\n\n\n\n","category":"function"},{"location":"reference/crossover/#NaiveGAflux.crossoverswap","page":"Crossover Operations","title":"NaiveGAflux.crossoverswap","text":"crossoverswap((v1,v2)::Tuple; pairgen=default_inputs_pairgen, selection=FilterMutationAllowed(), kwargs...)\n\nPerform crossoverswap! with v1 and v2 as output crossover points.\n\nInputs are selected from the feasible set (as determined by separablefrom and selection) through the supplied pairgen function.\n\nInputs v1 and v2 along with their entire graph are copied before operation is performed and originals are returned if operation is not successful.\n\nAdditional keyword arguments will be passed on to crossoverswap!.\n\n\n\n\n\n","category":"function"},{"location":"reference/crossover/#NaiveGAflux.crossoverswap!","page":"Crossover Operations","title":"NaiveGAflux.crossoverswap!","text":"crossoverswap!(v1::AbstractVertex, v2::AbstractVertex) = crossoverswap!(v1,v1,v2,v2)\ncrossoverswap!(vin1::AbstractVertex, vout1::AbstractVertex, vin2::AbstractVertex, vout2::AbstractVertex)\n\nSwap vertices vin1 to vout1 with vin2 and vout2 so that vin1 to vin2 is placed in the same position of the graph as vin2 to vout2 and vice versa.\n\nVertices must come from different graphs.\n\nThis operation can fail, leaving one or both graphs in a corrupted state where evaluating them results in an error (typically a DimensionMismatch error).\n\nReturn a tuple (success1, success2) where success1 is true if vin2 and vout2 was successfully swapped in to the graph which previously contained vin1 and vout1 and vice versa for success2.\n\n\n\n\n\n","category":"function"},{"location":"reference/crossover/#NaiveGAflux.default_pairgen","page":"Crossover Operations","title":"NaiveGAflux.default_pairgen","text":"default_pairgen(vs1, vs2, deviation = 0.0; rng=rng_default, compatiblefun = sameactdims, ind1 = rand(rng, eachindex(vs1)))\n\nReturn integers ind1 and ind2 so that vs1[ind1] and vs2[ind2] are a suitable pair for crossover.\n\nInput function compatiblefun(v1,v2) shall return true if v1 and v2 can be swapped and is used to determine the set of vertices to select from given.\n\nFrom the set of compatible vertices in vs2, the one which has the smallest relative topologial distance from vs1[ind2] is selected. The parameter devation can be used to randomly deviate from this where larger magnitude means more deviation.\n\n\n\n\n\n","category":"function"},{"location":"reference/crossover/#NaiveGAflux.default_inputs_pairgen","page":"Crossover Operations","title":"NaiveGAflux.default_inputs_pairgen","text":"default_inputs_pairgen(vs1, vs2, args...;kwargs...)\n\nSame as default_pairgen except it also ensures that shape changes of feature maps are consistent between the pairs.\n\nFeature map here refers to the shape of inputs to convolutional-type layers (Conv, Pooling) in dimensions other than the batch dimension or the channel dimension.\n\nFor example, for 2D convolutions, the arrays may have the shape WxHxCxB where C and B are the channel and batch dimensions respectively. The shape of the feature map in this case is then WxH.\n\nMore concretely, if x is the shape of a feature maps input to vin1 and f1(x) is the shape of the feature maps output from vout1 and f2 describes the same relation between vin2 and vout2 then only vertices vin2' for which f1(x) == f2(x) ∀ x for a selected vertex vin1 may be returned.\n\nThis function assumes that the last vertex in vs1 and vs2 are vout1 and vout2 respectively.\n\nThis prevents issues where graphs become inconsistent due to\n\nFeature maps become zero sized\nFeature maps of different sizes are merged (e.g. concatenated or element wise added)\n\nNote that this is more strict than needed as a change in the feature maps size does not necessarily result in 1) or 2).\n\n\n\n\n\n","category":"function"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"EditURL = \"https://github.com/DrChainsaw/NaiveGAflux.jl/blob/master/test/examples/iterators.jl\"","category":"page"},{"location":"examples/iterators/#Iterators","page":"Iterators","title":"Iterators","text":"","category":"section"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"While not part of the scope of this package, some simple utilities for iterating over data sets is provided.","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"The only iterator which is in some sense special for this package is RepeatPartitionIterator which produces iterators over a subset of its wrapped iterator. This is useful when one wants to ensure that all models see the same (possibly randomly augmented) data in the same order. Note that this is not certain to be the best strategy for finding good models for a given data set and this package does (intentionally) blur the lines a bit between model training protocol and architecture search.","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"data = reshape(collect(1:4*5), 4,5)\nlabels = collect(1:5)","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"Simple and fast batching of in-memory data is done by BatchIterator","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"biter = BatchIterator((data, labels), 2)\n@test size.(first(biter)) == ((4, 2), (2,))","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"Move data to gpu.","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"giter = GpuIterator(biter)\n@test first(giter) == first(biter) |> gpu","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"This is the only iterator which is \"special\" for this package:","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"rpiter = RepeatPartitionIterator(biter, 2)","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"It produces iterators over a subset of the wrapped iterator (2 batches in this case).","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"piter = first(rpiter)\n@test length(piter) == 2","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"This allows for easily training several models on the same subset of the data.","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"for modeli in 1:3\n    for ((feature, label), (expf, expl)) in zip(piter, biter)\n        @test feature == expf\n        @test label == expl\n    end\nend","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"StatefulGenerationIter is typically used in conjunction with TrainThenFitness to map a generation. number to an iterator from a RepeatPartitionIterator.","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"sgiter = StatefulGenerationIter(rpiter)\nfor (generationnr, topiter) in enumerate(rpiter)\n    gendata = collect(NaiveGAflux.itergeneration(sgiter, generationnr))\n    expdata = collect(topiter)\n    @test gendata == expdata\nend","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"TimedIterator is useful for preventing that models which take very long time to train/validate slow down the process.","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"timediter = TimedIterator(;\n                    timelimit=0.1,\n                    patience=4,\n                    timeoutaction = () -> TimedIteratorStop,\n                    accumulate_timeouts=false,\n                    base=1:100)\n\nlast = 0\nfor i in timediter\n    last = i\n    if i > 2\n        sleep(0.11)\n    end\nend\n@test last === 6 # Sleep after 2, then 4 patience.","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"","category":"page"},{"location":"examples/iterators/","page":"Iterators","title":"Iterators","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"EditURL = \"https://github.com/DrChainsaw/NaiveGAflux.jl/blob/master/test/examples/candidate.jl\"","category":"page"},{"location":"examples/candidate/#Candidate-Utilities","page":"Candidate Utilities","title":"Candidate Utilities","text":"","category":"section"},{"location":"examples/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"As seen in Fitness Functions, fitness strategies require an AbstractCandidate to compute fitness. To be used by NaiveGAflux, an AbstractCandidate needs to","category":"page"},{"location":"examples/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"Provide the data needed by the fitness strategy, most commonly the model but also things like lossfunctions and optimizers\nBe able to create a new version of itself given a function which maps its fields to new fields.","category":"page"},{"location":"examples/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"Capability 1. is generally performed through functions of the format someproperty(candidate; default) where in general someproperty(::AbstractCandidate; default=nothing) = default. The following such functions are currently implemented by NaiveGAflux:","category":"page"},{"location":"examples/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"model(c; default)  : Return a model\nopt(c; default)    : Return an optimizer\nlossfun(c; default) : Return a lossfunction","category":"page"},{"location":"examples/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"All such functions are obviously not used by all fitness strategies and some are used more often than others. Whether an AbstractCandidate returns something other than default generally depends on whether it is a hyperparameter which is being searched for or not. For example, the very simple CandidateModel has only a model while CandidateOptModel has both a model and an own optimizer which may be mutated/crossedover when evolving.","category":"page"},{"location":"examples/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"Capability 2. is what is used then evolving a candidate into a new version of itself. The function to implement for new AbstractCandidate types is newcand(c::MyCandidate, mapfields) which in most cases has the implementation newcand(c::MyCandidate, mapfield) = MyCandidate(map(mapfield, getproperty.(c, fieldnames(MyCandidate)))...). Furthermore, candidates must also be functors from Functors.jl to support things like GPU<->CPU movement.","category":"page"},{"location":"examples/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"Example with a new candidate type and a new fitness strategy for said type:","category":"page"},{"location":"examples/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"import Functors\nstruct ExampleCandidate <: AbstractCandidate\n    a::Int\n    b::Int\nend\naval(c::ExampleCandidate; default=nothing) = c.a\nbval(c::ExampleCandidate; default=nothing) = c.b\n\nFunctors.@functor ExampleCandidate\n\nstruct ExampleFitness <: AbstractFitness end\nNaiveGAflux._fitness(::ExampleFitness, c::AbstractCandidate) = aval(c; default=10) - bval(c; default=5)","category":"page"},{"location":"examples/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"Ok, this is alot of work for quite little in this dummy example.","category":"page"},{"location":"examples/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"@test fitness(ExampleFitness(), ExampleCandidate(4, 3)) === 1\n\nctime, examplemetric = fitness(TimeFitness(ExampleFitness()), ExampleCandidate(3,1))\n@test examplemetric === 2\n@test ctime > 0","category":"page"},{"location":"examples/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"","category":"page"},{"location":"examples/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"This page was generated using Literate.jl.","category":"page"},{"location":"autoflux/reference/reference/#AutoFlux-API-Reference","page":"AutoFlux API Reference","title":"AutoFlux API Reference","text":"","category":"section"},{"location":"autoflux/reference/reference/","page":"AutoFlux API Reference","title":"AutoFlux API Reference","text":"fit(x,y)","category":"page"},{"location":"autoflux/reference/reference/#NaiveGAflux.AutoFlux.fit-Tuple{Any, Any}","page":"AutoFlux API Reference","title":"NaiveGAflux.AutoFlux.fit","text":"fit(x, y; cb)\nfit(data::Tuple; cb, mdir)\n\nReturn a population of models fitted to the given data.\n\nThe type of model will depend on the shape of x.\n\nThe following model types are currently supported\n\n4D data -> ImageClassifier\n\nKeyword cb can be used to supply a callback function which will be called each generation with the current population as input.\n\nKeyword mdir is a directory which will be searched for serialized state from which the optimization will resume operations. Particularly useful in combination with cb=persist.\n\n\n\n\n\n","category":"method"},{"location":"autoflux/reference/reference/#ImageClassifiction","page":"AutoFlux API Reference","title":"ImageClassifiction","text":"","category":"section"},{"location":"autoflux/reference/reference/","page":"AutoFlux API Reference","title":"AutoFlux API Reference","text":"fit(::ImageClassifier, ::AbstractArray, ::AbstractArray)\nfit(::ImageClassifier, ::AbstractFitness, ::AbstractEvolution, stopcriterion)\nImageClassifier\nTrainSplitAccuracy\nTrainAccuracyVsSize\nAccuracyVsSize\nTrainIterConfig\nBatchedIterConfig\nShuffleIterConfig\nGlobalOptimizerMutation\nEliteAndSusSelection\nEliteAndTournamentSelection","category":"page"},{"location":"autoflux/reference/reference/#NaiveGAflux.AutoFlux.fit-Tuple{ImageClassifier, AbstractArray, AbstractArray}","page":"AutoFlux API Reference","title":"NaiveGAflux.AutoFlux.fit","text":"fit(c::ImageClassifier, x, y; cb, fitnesstrategy, evolutionstrategy, stopcriterion)\n\nReturn a population of image classifiers fitted to the given data.\n\nArguments\n\nc::ImageClassifier: Type of models to train. See ImageClassifier.\nx: Input data. Must be a 4D array.\ny: Output data. Can either be an 1D array in which case it is assumed that y is the raw labes (e.g. [\"cat\", \"dog\", \"cat\", ...]) or a 2D array in which case it is assumed that y is one-hot encoded.\ncb=identity: Callback function. After training and evaluating each generation but before evolution cb(population) will be called where population is the array of candidates. Useful for persistence and plotting.\nfitnesstrategy::AbstractFitnessStrategy=TrainSplitAccuracy(): Strategy for fitness from data.\nevolutionstrategy::AbstractEvolutionStrategy=EliteAndTournamentSelection(popsize=c.popsize): Strategy for evolution.\nstopcriterion: Takes the current population and returns true if fitting shall stop. Candidate fitness is available by calling fitness(c) where c is a member of the population.\n\n\n\n\n\n","category":"method"},{"location":"autoflux/reference/reference/#NaiveGAflux.AutoFlux.fit-Tuple{ImageClassifier, AbstractFitness, AbstractEvolution, Any}","page":"AutoFlux API Reference","title":"NaiveGAflux.AutoFlux.fit","text":"fit(c::ImageClassifier, fitnesstrategy::AbstractFitness, evostrategy::AbstractEvolution, stopcriterion; cb)\n\nReturn a population of image classifiers fitted to the given data.\n\nLower level version of fit to use when fit(c::ImageClassifier, x, y) doesn't cut it.\n\nArguments\n\nc::ImageClassifier: Type of models to train. See ImageClassifier.\nfitnessstrategy: An AbstractFitness used to compute the fitness metric for a candidate.\nevostrategy::AbstractEvolution: Evolution strategy to use. Population p will be evolved through p = evolve(evostrategy, p).\nstopcriterion: Takes the current population and returns true if fitting shall stop. Candidate fitness is available by calling fitness(c) where c is a member of the population.\ncb=identity: Callback function. After training and evaluating each generation but before evolution cb(population) will be called where population is the array of candidates. Useful for persistence and plotting.\n\n\n\n\n\n","category":"method"},{"location":"autoflux/reference/reference/#NaiveGAflux.AutoFlux.ImageClassification.ImageClassifier","page":"AutoFlux API Reference","title":"NaiveGAflux.AutoFlux.ImageClassification.ImageClassifier","text":"ImageClassifier\nImageClassifier(popinit, popsize, seed)\nImageClassifier(;popsize=50, seed=1, newpop=false, mdir=defaultdir(\"ImageClassifier\"); insize, outsize)\n\nType to make AutoFlux.fit train an image classifier using initial population size popsize using random seed seed.\n\nLoad models from mdir if directory contains models. If persistence is used (e.g. by providing cb=persist to fit) candidates will be stored in this directory.\n\nIf newpop is true the process will start with a new population and existing state in the specified directory will be overwritten.\n\n\n\n\n\n","category":"type"},{"location":"autoflux/reference/reference/#NaiveGAflux.AutoFlux.ImageClassification.TrainSplitAccuracy","page":"AutoFlux API Reference","title":"NaiveGAflux.AutoFlux.ImageClassification.TrainSplitAccuracy","text":"struct TrainSplitAccuracy{T} <: AbstractFitnessStrategy\n    TrainSplitAccuracy(;split, accuracyconfig, accuracyfitness, trainconfig, trainfitness)\n\nStrategy to train model on a subset of the training data and measure fitness as accuracy on the rest.\n\nSize of subset for accuracy fitness is ceil(Int, split * nobs) where nobs is the size of along the last dimension of the input.\n\nArguments\n\naccuracyconfig (default BatchedIterConfig()) determine how to iterate over the accuracy subset.\naccuracyfitness (default AccuracyVsSize) determine how to measure fitness based on accuracyconfig.\ntrainconfig (default TrainIterConfig()) determines how to iterate over the training subset. \ntrainfitness is a function accepting the iterator produced by trainconfig and the fitness strategy produced  by accuracyfitness and returns the AbstractFitness to be used (default TrainThenFitness wrapped in  GpuFitness).\n\n\n\n\n\n","category":"type"},{"location":"autoflux/reference/reference/#NaiveGAflux.AutoFlux.ImageClassification.TrainAccuracyVsSize","page":"AutoFlux API Reference","title":"NaiveGAflux.AutoFlux.ImageClassification.TrainAccuracyVsSize","text":"struct TrainAccuracyVsSize <: AbstractFitnessStrategy\nTrainAccuracyVsSize(;trainconfig, trainfitness)\n\nProduces an AbstractFitness which measures fitness accuracy on training data and based on number of parameters combined in the same way as is done for AccuracyVsSize.\n\nArguments\n\ntrainconfig (default TrainIterConfig()) determines how to iterate over the training subset. \ntrainfitness is a function accepting the iterator produced by trainconfig and the fitness strategy produced   by accuracyfitness and returns the AbstractFitness to be used (default TrainAccuracyFitness wrapped in   GpuFitness).\n\nBeware that fitness as accuracy on training data will make evolution favour overfitted candidates.\n\n\n\n\n\n","category":"type"},{"location":"autoflux/reference/reference/#NaiveGAflux.AutoFlux.ImageClassification.AccuracyVsSize","page":"AutoFlux API Reference","title":"NaiveGAflux.AutoFlux.ImageClassification.AccuracyVsSize","text":"AccuracyVsSize(data, accdigits=2, accwrap=identity)\n\nProduces an AbstractFitness which measures fitness accuracy on data and based on number of parameters.\n\nThe two are combined so that a candidate a which achieves higher accuracy rounded to the first accdigits digits compared to a candidate b will always have a better fitness.\n\nIf the first accdigits of accuracy is the same the candidate with fewer parameters will get higher fitness.\n\nAccuracy part of the fitness is calculated by accwrap(AccuracyFitness(data)).\n\n\n\n\n\n","category":"function"},{"location":"autoflux/reference/reference/#NaiveGAflux.AutoFlux.ImageClassification.TrainIterConfig","page":"AutoFlux API Reference","title":"NaiveGAflux.AutoFlux.ImageClassification.TrainIterConfig","text":"struct TrainIterConfig{T}\nTrainIterConfig(nbatches_per_gen, baseconfig)\nTrainIterConfig(;nbatches_per_gen=400, baseconfig=ShuffleIterConfig())\n\nStandard training strategy for creating a batched iterators from data. Data from baseconfig is cycled in partitions of nbatches_per_gen each generation using a RepeatPartitionIterator.\n\n\n\n\n\n","category":"type"},{"location":"autoflux/reference/reference/#NaiveGAflux.AutoFlux.ImageClassification.BatchedIterConfig","page":"AutoFlux API Reference","title":"NaiveGAflux.AutoFlux.ImageClassification.BatchedIterConfig","text":"struct BatchedIterConfig{T, V}\nBatchedIterConfig(;batchsize=32, dataaug=identity, iterwrap=identity)\n\nConfiguration for creating batch iterators from array data.\n\nThe function dataiter(s::BatchedIterConfig, x, y) creates an iterator which returns a tuple of batches from x and y respectively.\n\nMore specifically, the result of s.iterwrap(zip(s.dataaug(bx), by)) will be returned where bx and by are BatchIterators.\n\n\n\n\n\n","category":"type"},{"location":"autoflux/reference/reference/#NaiveGAflux.AutoFlux.ImageClassification.ShuffleIterConfig","page":"AutoFlux API Reference","title":"NaiveGAflux.AutoFlux.ImageClassification.ShuffleIterConfig","text":"struct ShuffleIterConfig{T, V}\nShuffleIterConfig(;batchsize=32, seed=123, dataaug=identity, iterwrap=identity)\n\nConfiguration for creating shuffled batch iterators from array data. Data will be re-shuffled every time the iterator restarts.\n\nThe function dataiter(s::ShuffleIterConfig, x, y) creates an iterator which returns a tuple of batches from x and y respectively.\n\nMore specifically, the result of s.iterwrap(Iterators.map(((x,y),) -> (s.dataaug(x), y), iter)) will be returned where iter is a BatchIterator over x and y with shuffle=true.\n\nNote there there is no upper bound on how many generations are supported as the returned iterator cycles the data indefinitely. Use e.g. Iterators.take(itr, cld(nepochs * nbatches_per_epoch, nbatches_per_gen)) to limit to nepochs epochs. \n\n\n\n\n\n","category":"type"},{"location":"autoflux/reference/reference/#NaiveGAflux.AutoFlux.ImageClassification.GlobalOptimizerMutation","page":"AutoFlux API Reference","title":"NaiveGAflux.AutoFlux.ImageClassification.GlobalOptimizerMutation","text":"struct GlobalOptimizerMutation{S<:AbstractEvolutionStrategy, F} <: AbstractEvolutionStrategy\nGlobalOptimizerMutation(base::AbstractEvolutionStrategy)\nGlobalOptimizerMutation(base::AbstractEvolutionStrategy, optfun)\n\nMaps the optimizer of each candidate in a population through optfun (default randomlrscale()).\n\nBasically a thin wrapper for global_optimizer_mutation.\n\nUseful for applying the same mutation to every candidate, e.g. global learning rate schedules which all models follow.\n\n\n\n\n\n","category":"type"},{"location":"autoflux/reference/reference/#NaiveGAflux.AutoFlux.ImageClassification.EliteAndSusSelection","page":"AutoFlux API Reference","title":"NaiveGAflux.AutoFlux.ImageClassification.EliteAndSusSelection","text":"struct EliteAndSusSelection <: AbstractEvolutionStrategy\nEliteAndSusSelection(popsize, nelites, evolve)\nEliteAndSusSelection(;popsize=50, nelites=2, evolve = crossovermutate())\n\nStandard evolution strategy.\n\nSelects nelites candidates to move on to the next generation without any mutation.\n\nAlso selects popsize - nelites candidates out of the whole population using SusSelection to evolve by applying random mutation.\n\nMutation operations are both applied to the model itself (change sizes, add/remove vertices/edges) as well as to the optimizer (change learning rate and optimizer algorithm).\n\nFinally, models are renamed so that the name of each vertex of the model of candidate i is prefixed with \"modeli\".\n\n\n\n\n\n","category":"type"},{"location":"autoflux/reference/reference/#NaiveGAflux.AutoFlux.ImageClassification.EliteAndTournamentSelection","page":"AutoFlux API Reference","title":"NaiveGAflux.AutoFlux.ImageClassification.EliteAndTournamentSelection","text":"struct EliteAndTournamentSelection <: AbstractEvolutionStrategy\nEliteAndTournamentSelection(popsize, nelites, k, p, evolve)\nEliteAndTournamentSelection(;popsize=50, nelites=2; k=2, p=1.0, evolve = crossovermutate())\n\nStandard evolution strategy.\n\nSelects nelites candidates to move on to the next generation without any mutation.\n\nAlso selects popsize - nelites candidates out of the whole population using TournamentSelection to evolve by applying random mutation.\n\nMutation operations are determined by evolve both applied to the model itself (change sizes, add/remove vertices/edges) as well as to the optimizer (change learning rate and optimizer algorithm).\n\nFinally, models are renamed so that the name of each vertex of the model of candidate i is prefixed with \"modeli\".\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#SearchSpacesAPI","page":"Search Spaces","title":"Search Spaces","text":"","category":"section"},{"location":"reference/searchspace/#Parameter-Spaces","page":"Search Spaces","title":"Parameter Spaces","text":"","category":"section"},{"location":"reference/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"SingletonParSpace \nParSpace\nCoupledParSpace","category":"page"},{"location":"reference/searchspace/#NaiveGAflux.SingletonParSpace","page":"Search Spaces","title":"NaiveGAflux.SingletonParSpace","text":"SingletonParSpace{N, T} <:AbstractParSpace{N, T}\nSingletonParSpace(p::T...)\nSingleton2DParSpace(p::T)\n\nSingleton search space. Has exactly one value per dimension.\n\nSingleton2DParSpace is a convenience constructor for a 2D SingletonParSpace of [p, p].\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.ParSpace","page":"Search Spaces","title":"NaiveGAflux.ParSpace","text":"ParSpace{N, T} <:AbstractParSpace{N, T}\nParSpace(p::AbstractVector{T}...)\nParSpace1D(p...)\nParSpace2D(p::AbstractVector)\n\nSearch space for parameters.\n\nReturn independent uniform random values for all N dimensions from the search space when invoked.\n\nParSpace1D is a convenience constructor for an 1D ParSpace of p. ParSpace2D is a convenience constructor for a 2D ParSpace of [p, p]`.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.CoupledParSpace","page":"Search Spaces","title":"NaiveGAflux.CoupledParSpace","text":"CoupledParSpace{N, T} <:AbstractParSpace{N, T}\nCoupledParSpace(p::AbstractParSpace{1, T}, N) \nCoupledParSpace(p::AbstractVector{T}, N)\n\nSearch space for parameters.\n\nReturn the same uniformly sampled value for all N dimensions from the search space when invoked.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#LAyerSearchSpaceAPI","page":"Search Spaces","title":"Layer Search Spaces","text":"","category":"section"},{"location":"reference/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"BaseLayerSpace \nNamedLayerSpace\nLoggingLayerSpace\nDenseSpace\nConvSpace\nBatchNormSpace\nPoolSpace\nLayerVertexConf\nShielded\nConcConf","category":"page"},{"location":"reference/searchspace/#NaiveGAflux.BaseLayerSpace","page":"Search Spaces","title":"NaiveGAflux.BaseLayerSpace","text":"BaseLayerSpace\nBaseLayerSpace(outsizes, activationfunctions)\n\nSearch space for basic attributes common to all layers.\n\noutsizes is the output sizes (number of neurons). activationfunctions is the activation functions.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.NamedLayerSpace","page":"Search Spaces","title":"NaiveGAflux.NamedLayerSpace","text":"NamedLayerSpace <:AbstractLayerSpace\nNamedLayerSpace(name::String, s::AbstractLayerSpace)\n\nAdds a name to an AbstractLayerSpace.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.LoggingLayerSpace","page":"Search Spaces","title":"NaiveGAflux.LoggingLayerSpace","text":"LoggingLayerSpace <: AbstractLayerSpace\nLoggingLayerSpace(s::AbstractLayerSpace; level=Logging.Debug, nextlogfun=() -> PrefixLogger(\"   \"))\nLoggingLayerSpace(msgfun, s::AbstractLayerSpace; level = Logging.Debug, nextlogfun = () -> PrefixLogger(\"   \"))\nLoggingLayerSpace(level::LogLevel, msgfun, nextlogfun, s::AbstractLayerSpace)\n\nLogs msgfun(layer) at loglevel level after creating a layer from s.\n\nCalling nextlogfun() produces an AbstractLogger which will be used when creating layer from s.\n\nBy default, this is used to add a level of indentation to subsequent logging calls which makes logs of hierarchical archspaces easier to read. Set nextlogfun = () -> current_logger() to remove this behaviour.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.DenseSpace","page":"Search Spaces","title":"NaiveGAflux.DenseSpace","text":"DenseSpace <:AbstractLayerSpace\nDenseSpace(base::BaseLayerSpace)\nDenseSpace(outsizes, activations)\n\nSearch space of Dense layers.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.ConvSpace","page":"Search Spaces","title":"NaiveGAflux.ConvSpace","text":"ConvSpace{N} <:AbstractLayerSpace\n\nConvSpace{N}(;outsizes, kernelsizes, activations=identity, strides=1, dilations=1, paddings=SamePad(), convfuns=Conv)\nConvSpace(convfun::AbstractParSpace, base::BaseLayerSpace, ks::AbstractParSpace, stride::AbstractParSpace, dilation::AbstractParSpace, pad)\n\nSearch space of ND convolutional layers.\n\nConstructor with keyword arguments takes scalars, vectors or AbstractParSpaces as inputs.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.BatchNormSpace","page":"Search Spaces","title":"NaiveGAflux.BatchNormSpace","text":"BatchNormSpace <:AbstractLayerSpace\nBatchNormSpace(activationfunctions...)\nBatchNormSpace(activationfunctions::AbstractVector)\n\nSearch space of BatchNorm layers.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.PoolSpace","page":"Search Spaces","title":"NaiveGAflux.PoolSpace","text":"PoolSpace{N} <:AbstractLayerSpace\nPoolSpace{N}(;windowsizes, strides=1, paddings=SamePad(), poolfun=[MaxPool, MeanPool])\n\nSearch space of ND pooling layers.\n\nConstructor with keyword arguments takes scalars/tuples, vectors or AbstractParSpaces as inputs.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.LayerVertexConf","page":"Search Spaces","title":"NaiveGAflux.LayerVertexConf","text":"LayerVertexConf\nLayerVertexConf(layerfun, traitfun)\n\nGeneric configuration template for computation graph vertices with Flux layers as their computation.\n\nBoth layerfun and traitfun are forwarded to NaiveNASflux.fluxvertex.    \n\nIntention is to make it easy to add logging, validation and pruning metrics in an uniform way.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.Shielded","page":"Search Spaces","title":"NaiveGAflux.Shielded","text":"Shielded(base=LayerVertexConf(); allowed = tuple())\n\nCreate a LayerVertexConf which is shielded from mutation.\n\nKeyword allowed can be used to supply a tuple (or array) of AbstractMutation types to allow.\n\n\n\n\n\n","category":"function"},{"location":"reference/searchspace/#NaiveGAflux.ConcConf","page":"Search Spaces","title":"NaiveGAflux.ConcConf","text":"ConcConf\nConcConf(layerfun, traitfun)\n\nGeneric configuration template for concatenation of vertex outputs.\n\nBoth layerfun and traitfun are forwarded to NaiveNASflux.concat.  \n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#Architecture-Search-Spaces","page":"Search Spaces","title":"Architecture Search Spaces","text":"","category":"section"},{"location":"reference/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"NoOpArchSpace\nLoggingArchSpace\nVertexSpace\nArchSpace\nConditionalArchSpace\nRepeatArchSpace\nArchSpaceChain\nForkArchSpace\nResidualArchSpace\nFunctionSpace\nGlobalPoolSpace","category":"page"},{"location":"reference/searchspace/#NaiveGAflux.NoOpArchSpace","page":"Search Spaces","title":"NaiveGAflux.NoOpArchSpace","text":"NoOpArchSpace <: AbstractArchSpace\n\nReturns input vertex without any modification.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.LoggingArchSpace","page":"Search Spaces","title":"NaiveGAflux.LoggingArchSpace","text":"LoggingArchSpace <: AbstractArchSpace\nLoggingArchSpace(s::AbstractArchSpace; level=Logging.Debug, nextlogfun=in -> PrefixLogger(\"   \"))\nLoggingArchSpace(msgfun, s::AbstractArchSpace; level=Logging.Debug, nextlogfun=in -> PrefixLogger(\"   \"))\nLoggingArchSpace(msgfun::Function, level::LogLevel, nextlogfun, s::AbstractArchSpace)\n\nLogs msgfun(vertex) at loglevel level after creating a vertex from s.\n\nCalling nextlogfun(in) where in is the input vertex produces an AbstractLogger which will be used when creating vertex from s.\n\nBy default, this is used to add a level of indentation to subsequent logging calls which makes logs of hierarchical archspaces easier to read. Set nextlogfun = e -> current_logger() to remove this behaviour.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.VertexSpace","page":"Search Spaces","title":"NaiveGAflux.VertexSpace","text":"VertexSpace <:AbstractArchSpace\nVertexSpace([conf::LayerVertexConf], lspace::AbstractLayerSpace)\n\nSearch space of one AbstractVertex with compuation drawn from lspace.\n\nconf is used to attach other metadata to the vertex. See LayerVertexConf.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.ArchSpace","page":"Search Spaces","title":"NaiveGAflux.ArchSpace","text":"ArchSpace <:AbstractArchSpace\nArchSpace(ss::AbstractLayerSpace...; conf=LayerVertexConf()) \nArchSpace(ss::AbstractArchSpace...)\n\nSearch space of AbstractArchSpaces.\n\nDraws one vertex from one of ss (uniformly selected) when invoked.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.ConditionalArchSpace","page":"Search Spaces","title":"NaiveGAflux.ConditionalArchSpace","text":"ConditionalArchSpace{P, S1, S2} <: AbstractArchSpace\nConditionalArchSpace(predicate, iftrue, iffalse=NoOpArchSpace())\nConditionalArchSpace(;predicate, iftrue, iffalse=NoOpArchSpace())\n\nUse iftrue if predicate(invertex) returns true, iffalse otherwise.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.RepeatArchSpace","page":"Search Spaces","title":"NaiveGAflux.RepeatArchSpace","text":"RepeatArchSpace <:AbstractArchSpace\nRepeatArchSpace(s::AbstractArchSpace, r::Integer) \nRepeatArchSpace(s::AbstractArchSpace, r::AbstractVector{<:Integer})\n\nSearch space of repetitions of another AbstractArchSpace where number of repetitions is uniformly drawn from r.\n\nOutput of each generated candidate is input to next and the last output is returned.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.ArchSpaceChain","page":"Search Spaces","title":"NaiveGAflux.ArchSpaceChain","text":"ArchSpaceChain <:AbstractArchSpace\nArchSpaceChain(s::AbstractArchSpace...)\n\nChains multiple AbstractArchSpaces after each other.\n\nInput vertex will be used to generate an output vertex from the first AbstractArchSpace in the chain which is then used to generate a next output vertex from the next AbstractArchSpace in the chain and so on. The output from the last AbstractArchSpace is returned.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.ForkArchSpace","page":"Search Spaces","title":"NaiveGAflux.ForkArchSpace","text":"ForkArchSpace <:AbstractArchSpace\nForkArchSpace(s::AbstractArchSpace, r::Integer; conf=ConcConf())\nForkArchSpace(s::AbstractArchSpace, r::AbstractVector{<:Integer}; conf=ConcConf())\n\nSearch space of parallel paths from another AbstractArchSpace where number of paths is uniformly drawn from r.\n\nInput vertex is input to a number of paths drawn from an AbstractParSpace. Concatenation of paths is output.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.ResidualArchSpace","page":"Search Spaces","title":"NaiveGAflux.ResidualArchSpace","text":"ResidualArchSpace <:AbstractArchSpace\nResidualArchSpace(s::AbstractArchSpace, [conf::VertexConf])\n\nTurns the wrapped AbstractArchSpace into a residual.\n\nReturn x = y + in where y is drawn from the wrapped AbstractArchSpace when invoked with in as input vertex.\n\nconf is used to decorate trait and wrap the computation (e.g in an ActivationContribution). \n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.FunctionSpace","page":"Search Spaces","title":"NaiveGAflux.FunctionSpace","text":"FunctionSpace <: AbstractArchSpace\nFunctionSpace(funs...; namesuff::String, conf=LayerVertexConf(ActivationContribution, validated() ∘ default_logging()))\n\nReturn a SizeInvariant vertex representing fun(x) when invoked with in as input vertex where x is output of in where fun is uniformly selected from funs.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.GlobalPoolSpace","page":"Search Spaces","title":"NaiveGAflux.GlobalPoolSpace","text":"GlobalPoolSpace(Ts...)\nGlobalPoolSpace(conf::LayerVertexConf, Ts...)\n\nShort for FunctionSpace with global average or global max pooling.\n\nAlso adds a MutationShield to prevent the vertex from being removed by default.\n\n\n\n\n\n","category":"function"},{"location":"reference/searchspace/#Weight-Initialization","page":"Search Spaces","title":"Weight Initialization","text":"","category":"section"},{"location":"reference/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"DefaultWeightInit\nIdentityWeightInit\nZeroWeightInit","category":"page"},{"location":"reference/searchspace/#NaiveGAflux.DefaultWeightInit","page":"Search Spaces","title":"NaiveGAflux.DefaultWeightInit","text":"DefaultWeightInit <: AbstractWeightInit\n\nUse the layer default weight initialization.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.IdentityWeightInit","page":"Search Spaces","title":"NaiveGAflux.IdentityWeightInit","text":"IdentityWeightInit <: AbstractWeightInit\nIdentityWeightInit()\n\nInitialize weights with an identity mapping.\n\n\n\n\n\n","category":"type"},{"location":"reference/searchspace/#NaiveGAflux.ZeroWeightInit","page":"Search Spaces","title":"NaiveGAflux.ZeroWeightInit","text":"ZeroWeightInit <: AbstractWeightInit\nZeroWeightInit()\n\nInitialize weights as zeros.\n\nMain use case is to let residual layers be and identity mapping\n\n\n\n\n\n","category":"type"},{"location":"autoflux/#AutoFlux","page":"AutoFlux","title":"AutoFlux","text":"","category":"section"},{"location":"autoflux/","page":"AutoFlux","title":"AutoFlux","text":"AutoFlux is a neural architecture search application built on top of NaiveGAflux. It is designed to have a single high level API entry point for kicking of the search:","category":"page"},{"location":"autoflux/","page":"AutoFlux","title":"AutoFlux","text":"using NaiveGAflux.AutoFlux\nmodels = fit(data)","category":"page"},{"location":"autoflux/","page":"AutoFlux","title":"AutoFlux","text":"Where models is the whole population of models found after search stopped.","category":"page"},{"location":"autoflux/","page":"AutoFlux","title":"AutoFlux","text":"It is possible (and strongly recommended) to supply a callback function which will receive the whole population of models as input after fitness for each generation has been calculated. A few useful functions are provided:","category":"page"},{"location":"autoflux/","page":"AutoFlux","title":"AutoFlux","text":"using NaiveGAflux, Plots\n# Persist the whole population in directory models/CIFAR10 so that optimization can be resumed if aborted:\nmodels = fit(CIFAR10.traindata(), cb=persist, mdir=\"models/CIFAR10\")\n\n# Plot best and average fitness for each generation\nplotfitness = PlotFitness(plot, \"models/CIFAR10\");\n# Plot data will be serialized in a subdir of \"models/CIFAR10\" for later postprocessing and for resuming optimization.\nmodels = fit(CIFAR10.traindata(), cb=plotfitness, mdir=\"models/CIFAR10\")\n\n\n# Scatter plots from examples above:\nscatterpop = ScatterPop(scatter, \"models/CIFAR10\");\nscatteropt = ScatterOpt(scatter, \"models/CIFAR10\");\n\n# Combine multiple plots in one figure:\nmultiplot = MultiPlot(display ∘ plot, plotfitness, scatterpop, scatteropt)\n\n# Combine multiple callbacks in one function:\ncallbacks = CbAll(persist, multiplot)\n\nmodels = fit(CIFAR10.traindata(), cb=callbacks, mdir=\"models/CIFAR10\")","category":"page"},{"location":"autoflux/","page":"AutoFlux","title":"AutoFlux","text":"The ambition level is to provide something like a more flexible version of Large-Scale Evolution of Image Classifiers  with the following main improvements:","category":"page"},{"location":"autoflux/","page":"AutoFlux","title":"AutoFlux","text":"Support for other model types (not done yet).\nFiner search granularity, i.e. about one 1 epoch of training per generation.\nNo hardcoded training protocol, it is part of the search.\nSmaller population size feasible to run on a single machine.","category":"page"},{"location":"autoflux/","page":"AutoFlux","title":"AutoFlux","text":"Note that the set of modifications of AutoFlux is very different from Large-Scale Evolution of Image Classifiers,  but neither is a strict subset of the other so it is difficult assess which one has the most generic search space. ","category":"page"},{"location":"autoflux/","page":"AutoFlux","title":"AutoFlux","text":"In its current state, AutoFlux is perhaps best viewed as a combined example and end-to-end test of NaiveGAflux.  It is more focused on making use of all components of NaiveGAflux rather than winning benchmarks. In particular, it makes the very conscious and opinionated choice of not seeding the search space with models which are known to work well as this is a bit against the point of searching for an architecture. If searching for a benchmark  winner is the goal, one might want to use the lower level APIs to start with a population of models which are  known to perform well.","category":"page"},{"location":"autoflux/#Performance","page":"AutoFlux","title":"Performance","text":"","category":"section"},{"location":"autoflux/","page":"AutoFlux","title":"AutoFlux","text":"I develop this project on my spare time as a hobby and I don't have access to large amounts of computation.  Thus providing benchmarking numbers with any kind of confidence behind them is very time consuming. Rough  numbers for CIFAR10 is at least around 90% test accuracy for the best model after about 80 generations with  one epoch per generation. A best half population ensemble gives about 1% improvement. A few other tricks,  such as increasing the number of epochs for training (while decreasing population size) after a couple of  generations also seem to yield about 1% improvement.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"EditURL = \"https://github.com/DrChainsaw/NaiveGAflux.jl/blob/master/test/examples/quicktutorial.jl\"","category":"page"},{"location":"examples/quicktutorial/#Quick-Tutorial","page":"Quick Tutorial","title":"Quick Tutorial","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Here is a very basic example just to get a feeling for the package. We set up a simple search for number of fully connected layers and their widths.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"using NaiveGAflux, Flux, Random\nRandom.seed!(NaiveGAflux.rng_default, 0)\n\nnlabels = 3\nninputs = 5","category":"page"},{"location":"examples/quicktutorial/#Step-1:-Create-initial-models.","page":"Quick Tutorial","title":"Step 1: Create initial models.","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Search space: 2-4 dense layers of width 3-10.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"layerspace = VertexSpace(DenseSpace(3:10, [identity, relu, elu, selu]))\ninitial_hidden = RepeatArchSpace(layerspace, 1:3)","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Output layer has fixed size and is shielded from mutation.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"outlayer = VertexSpace(Shielded(), DenseSpace(nlabels, identity))\ninitial_searchspace = ArchSpaceChain(initial_hidden, outlayer)","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Sample 5 models from the initial search space and make an initial population.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"samplemodel(invertex) = CompGraph(invertex, initial_searchspace(invertex))\nmodels = [samplemodel(denseinputvertex(\"input\", ninputs)) for _ in 1:5]\n@test nvertices.(models) == [4, 3, 4, 5, 3]\n\npopulation = Population(CandidateModel.(models))\n@test generation(population) == 1","category":"page"},{"location":"examples/quicktutorial/#Step-2:-Set-up-fitness-function:","page":"Quick Tutorial","title":"Step 2: Set up fitness function:","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Train model for one epoch using datasettrain, then measure accuracy on datasetvalidate. We use dummy data here just to make stuff run.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"onehot(y) = Flux.onehotbatch(y, 1:nlabels)\nbatchsize = 4\ndatasettrain    = [(randn(ninputs, batchsize), onehot(rand(1:nlabels, batchsize)))]\ndatasetvalidate = [(randn(ninputs, batchsize), onehot(rand(1:nlabels, batchsize)))]\n\nfitnessfunction = TrainThenFitness(;\n    dataiter = datasettrain,\n    defaultloss = Flux.logitcrossentropy, # Will be used if not provided by the candidate\n    defaultopt = ADAM(), # Same as above. State is wiped after training to prevent memory leaks\n    fitstrat = AccuracyFitness(datasetvalidate) # This is what creates our fitness value after training\n)","category":"page"},{"location":"examples/quicktutorial/#Step-3:-Define-how-to-search-for-new-candidates","page":"Quick Tutorial","title":"Step 3: Define how to search for new candidates","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"We choose to evolve the existing ones through mutation.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"VertexMutation selects valid vertices from the graph to mutate. MutationProbability applies mutation m with a probability of p. Lets create a short helper for brevity:","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"mp(m, p) = VertexMutation(MutationProbability(m, p))","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Change size (60% chance) and/or add a layer (40% chance) and/or remove a layer (40% chance). You might want to use lower probabilities than this.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"changesize = mp(NoutMutation(-0.2, 0.2), 0.6)\naddlayer = mp(AddVertexMutation(layerspace), 0.4)\nremlayer = mp(RemoveVertexMutation(), 0.4)\nmutation = MutationChain(changesize, remlayer, addlayer)","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Selection: The two best models are not changed, then create three new models by applying the mutations above to three of the five models with higher fitness giving higher probability of being selected.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"elites = EliteSelection(2)\nmutate = SusSelection(3, EvolveCandidates(evolvemodel(mutation)))\nselection = CombinedEvolution(elites, mutate)","category":"page"},{"location":"examples/quicktutorial/#Step-4:-Run-evolution","page":"Quick Tutorial","title":"Step 4: Run evolution","text":"","category":"section"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"newpopulation = evolve(selection, fitnessfunction, population)\n@test newpopulation != population\n@test generation(newpopulation) == 2","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Repeat until a model with the desired fitness is found.","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"newnewpopulation = evolve(selection, fitnessfunction, newpopulation)\n@test newnewpopulation != newpopulation\n@test generation(newnewpopulation) == 3\nbestfitness, bestcandnr = findmax(fitness, newnewpopulation)\n@test model(newnewpopulation[bestcandnr]) isa CompGraph","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"Maybe in a loop :)","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"","category":"page"},{"location":"examples/quicktutorial/","page":"Quick Tutorial","title":"Quick Tutorial","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"EditURL = \"https://github.com/DrChainsaw/NaiveGAflux.jl/blob/master/test/examples/fitness.jl\"","category":"page"},{"location":"examples/fitness/#Fitness-Functions","page":"Fitness Functions","title":"Fitness Functions","text":"","category":"section"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"A handful of ways to compute the fitness of a model are supplied. Apart from the obvious accuracy on some (typically held out) data set, it is also possible to measure fitness as how many (few) parameters a model has and how long it takes to compute the fitness. Fitness metrics can of course be combined to create objectives which balance several factors.","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"As seen in the Quick Tutorial, training of a model is just another fitness strategy. This might seem unintuitive at first, but reading it out like \"the chosen fitness strategy is to first train the model for N batches, then compute the accuracy on the validation set\" makes sense. The practical advantages are that it becomes straight forward to implement fitness strategies which don't involve model training (e.g. using the neural tangent kernel) as well as fitness strategies which measure some aspect of the model training (e.g. time to train for X iterations or training memory consumption). Another useful property is that models which produce NaNs or Infs or take very long to train can be assigned a low fitness score.","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"Function to compute fitness for does not have to be a CompGraph, or even a neural network. It must be wrapped in an AbstractCandidate since fitness functions generally need to query the candidate for things which affect the fitness, such as the model but also things like optimizers and loss functions.","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"candidate1 = CandidateModel(x -> 3:-1:1)\ncandidate2 = CandidateModel(Dense(ones(Float32, 3,3), collect(Float32, 1:3)))","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"AccuracyFitness compuates fitness as accuracy on the provided data set.","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"accfitness = AccuracyFitness([(ones(Float32, 3, 1), 1:3)])\n\n@test fitness(accfitness, candidate1) == 0\n@test fitness(accfitness, candidate2) == 1","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"TimeFitness measures how long time it takes to evaluate the fitness and add that in addition to the accuracy.","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"timedfitness = TimeFitness(accfitness)\nc1time, c1acc = fitness(timedfitness, candidate1)\nc2time, c2acc = fitness(timedfitness, candidate2)\n\n@test c1acc == 0\n@test c2acc == 1\n\n@test c1time > 0\n@test c2time > 0","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"SizeFitness uses the number of parameters to compute fitness.","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"bigmodelfitness = SizeFitness()\n@test fitness(bigmodelfitness, candidate1) == 0\n@test fitness(bigmodelfitness, candidate2) == 12","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"One typically wants to map high number of params to lower fitness. MapFitness allow use to remap the fitness value from another fitness function.","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"smallmodelfitness = MapFitness(bigmodelfitness) do nparameters\n    return min(1, 1 / nparameters)\nend\n@test fitness(smallmodelfitness, candidate1) == 1\n@test fitness(smallmodelfitness, candidate2) == 1/12","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"Combining fitness is straight forward with AggFitness","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"combined = AggFitness(+, accfitness, smallmodelfitness, bigmodelfitness)\n\n@test fitness(combined, candidate1) == 1\n@test fitness(combined, candidate2) == 13 + 1/12","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"GpuFitness moves the candidates to GPU (using Flux.gpu) before computing the wrapped fitness. Note that any data in the wrapped fitness must also be moved to the same GPU before being fed to the model.","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"gpuaccfitness = GpuFitness(AccuracyFitness(GpuIterator(accfitness.dataset)))\n\n@test fitness(gpuaccfitness, candidate1) == 0\n@test fitness(gpuaccfitness, candidate2) == 1","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"","category":"page"},{"location":"examples/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"This page was generated using Literate.jl.","category":"page"},{"location":"reference/evolution/#EvolutionStrategiesAPI","page":"Evolution Strategies","title":"Evolution Strategies","text":"","category":"section"},{"location":"reference/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"evolve\nNoOpEvolution\nEliteSelection\nSusSelection\nTournamentSelection\nCombinedEvolution\nEvolutionChain\nPairCandidates\nShuffleCandidates\nEvolveCandidates\nAfterEvolution","category":"page"},{"location":"reference/evolution/#NaiveGAflux.evolve","page":"Evolution Strategies","title":"NaiveGAflux.evolve","text":"evolve(e::AbstractEvolution, population)\n\nReturn a new population evolved by e.\n\nNew population may or may not contain same individuals as before.\n\n\n\n\n\nevolve(e::AbstractEvolution, f::AbstractFitness, p::Population)\n\nReturn a new population fitted by f and evolved by e.\n\nThis is done by first replacing each member of p with a FittedCandidate with fitness computed by f.\n\nThen evolve population into a new population using e. New population may or may not contain same individuals as before.\n\n\n\n\n\n","category":"function"},{"location":"reference/evolution/#NaiveGAflux.NoOpEvolution","page":"Evolution Strategies","title":"NaiveGAflux.NoOpEvolution","text":"NoOpEvolution <: AbstractEvolution\nNoOpEvolution()\n\nDoes not evolve the given population.\n\n\n\n\n\n","category":"type"},{"location":"reference/evolution/#NaiveGAflux.EliteSelection","page":"Evolution Strategies","title":"NaiveGAflux.EliteSelection","text":"EliteSelection <: AbstractEvolution\nEliteSelection(nselect::Integer, evo=NoOpEvolution())\n\nSelects the nselect highest fitness candidates to be passed on to evo.\n\n\n\n\n\n","category":"type"},{"location":"reference/evolution/#NaiveGAflux.SusSelection","page":"Evolution Strategies","title":"NaiveGAflux.SusSelection","text":"SusSelection <: AbstractEvolution\nSusSelection(nselect, evo, rng=rng_default)\n\nSelects candidates for further evolution using stochastic universal sampling.\n\n\n\n\n\n","category":"type"},{"location":"reference/evolution/#NaiveGAflux.TournamentSelection","page":"Evolution Strategies","title":"NaiveGAflux.TournamentSelection","text":"TournamentSelection <: AbstractEvolution\nTournamentSelection(nselect, k, p::Real, evo, rng=rng_default)\n\nSelects candidates for further evolution using tournament selection.\n\nHolds nselect tournaments with one winner each where each tournament has k random candidates from the given population.\n\nWinner of a tournament is selected as the candidate with highest fitness with a probability p, second highest fitness with a probability p(p-1), third highest fitness with a probability of p((p-1)^2) and so on.\n\n\n\n\n\n","category":"type"},{"location":"reference/evolution/#NaiveGAflux.CombinedEvolution","page":"Evolution Strategies","title":"NaiveGAflux.CombinedEvolution","text":"CombinedEvolution <: AbstractEvolution\nCombinedEvolution(evos::AbstractArray)\nCombinedEvolution(evos...)\n\nCombines the evolved populations from several AbstractEvolutions into one population.\n\n\n\n\n\n","category":"type"},{"location":"reference/evolution/#NaiveGAflux.EvolutionChain","page":"Evolution Strategies","title":"NaiveGAflux.EvolutionChain","text":"EvolutionChain <: AbstractEvolution\nEvolutionChain(evos::AbstractArray)\nEvolutionChain(evos...)\n\nChains multiple AbstractEvolutions in a sequence so that output from the first is input to the next and so on.\n\n\n\n\n\n","category":"type"},{"location":"reference/evolution/#NaiveGAflux.PairCandidates","page":"Evolution Strategies","title":"NaiveGAflux.PairCandidates","text":"PairCandidates <: AbstractEvolution\nPairCandidates(evo::AbstractEvolution)\n\nCreates pairs of candidates in a population and calls evolve(evo, pairs) where pairs is the array of pairs.\n\n\n\n\n\n","category":"type"},{"location":"reference/evolution/#NaiveGAflux.ShuffleCandidates","page":"Evolution Strategies","title":"NaiveGAflux.ShuffleCandidates","text":"ShuffleCandidates\nShuffleCandidates()\nShuffleCandidates(rng)\n\nShuffles the population using rng.\n\nUseful with PairCandidates in case the prior selection does not shuffle the population.\n\n\n\n\n\n","category":"type"},{"location":"reference/evolution/#NaiveGAflux.EvolveCandidates","page":"Evolution Strategies","title":"NaiveGAflux.EvolveCandidates","text":"EvolveCandidates <: AbstractEvolution\nEvolveCandidates(fun)\n\nApplies fun(c) for each candidate c in a given population.\n\nUseful with evolvemodel.\n\n\n\n\n\n","category":"type"},{"location":"reference/evolution/#NaiveGAflux.AfterEvolution","page":"Evolution Strategies","title":"NaiveGAflux.AfterEvolution","text":"AfterEvolution <: AbstractEvolution\nAfterEvolution(evo, fun)\n\nReturn fun(newpop) where newpop = evolve(e.evo, pop) where pop is original population to evolve.\n\n\n\n\n\n","category":"type"},{"location":"reference/candidate/#CandidateUtilitiesAPI","page":"Candidate Utilities","title":"Candidate Utilities","text":"","category":"section"},{"location":"reference/candidate/","page":"Candidate Utilities","title":"Candidate Utilities","text":"CandidateModel \nCandidateOptModel\nCandidateDataIterMap\nFittedCandidate\nMapCandidate\nPopulation\nmodel\nopt\nlossfun\nBatchSizeIteratorMap\nAbstractIteratorMap","category":"page"},{"location":"reference/candidate/#NaiveGAflux.CandidateModel","page":"Candidate Utilities","title":"NaiveGAflux.CandidateModel","text":"CandidateModel <: Candidate\nCandidateModel(model)\n\nA candidate model which can be accessed by model(c) for CandidateModel c.\n\n\n\n\n\n","category":"type"},{"location":"reference/candidate/#NaiveGAflux.CandidateOptModel","page":"Candidate Utilities","title":"NaiveGAflux.CandidateOptModel","text":"CandidateOptModel <: AbstractCandidate\nCandidateOptModel(optimizer, candidate)\n\nA candidate adding an optimizer to another candidate. The optimizer is accessed by [opt(c)] for CandidateOptModel c.\n\n\n\n\n\n","category":"type"},{"location":"reference/candidate/#NaiveGAflux.CandidateDataIterMap","page":"Candidate Utilities","title":"NaiveGAflux.CandidateDataIterMap","text":"CandidateDataIterMap{T<:AbstractIteratorMap, C<:AbstractCandidate}     \nCandidateDataIterMap(itermap::AbstractIteratorMap, c::AbstractCandidate)\n\nMaps training and validation data iterators using iteratormap for the wrapped candidate c.\n\nUseful for searching for hyperparameters related to training and validation data, such as augmentation and batch size.\n\nWhile one generally don't want to augment the validation data, it is useful to select the largest possible batch size for validation for speed reasons.\n\n\n\n\n\n","category":"type"},{"location":"reference/candidate/#NaiveGAflux.FittedCandidate","page":"Candidate Utilities","title":"NaiveGAflux.FittedCandidate","text":"FittedCandidate{F, C} <: AbstractWrappingCandidate\nFittedCandidate(c::AbstractCandidate, fitnessvalue, generation)\nFittedCandidate(c::AbstractCandidate, fitnessfun::AbstractFitness, generation)\n\nAn AbstractCandidate with a computed fitness value. Will compute the fitness value if provided an AbstractFitness.\n\nBasically a container for results so that fitness does not need to be recomputed to e.g. check stopping conditions. \n\nAlso useful for fitness smoothing, e.g. with EwmaFitness as it gives access to previous fitness value.\n\n\n\n\n\n","category":"type"},{"location":"reference/candidate/#NaiveGAflux.Population","page":"Candidate Utilities","title":"NaiveGAflux.Population","text":"struct Population{N, P}\nPopulation(gen, members)\nPopulation(members)\n\nBasic population type which just adds generation counting to its members.\n\nEvolving the population returns a new Population with the generation counter incremented.\n\n\n\n\n\n","category":"type"},{"location":"reference/candidate/#NaiveGAflux.model","page":"Candidate Utilities","title":"NaiveGAflux.model","text":"model(c::AbstractCandidate; [default])\n\nReturn the model of candidate c if c has a model, default (which defaults to nothing) otherwise.\n\n\n\n\n\nmodel(f, c::AbstractCandidate; [default])\n\nReturn the result of f([model(c; default)]). \n\n\n\n\n\n","category":"function"},{"location":"reference/candidate/#NaiveGAflux.opt","page":"Candidate Utilities","title":"NaiveGAflux.opt","text":"opt(c::AbstractCandidate; [default])\n\nReturn the optimizer of candidate c if c has an optimizer, default (which defaults to nothing) otherwise.\n\n\n\n\n\n","category":"function"},{"location":"reference/candidate/#NaiveGAflux.lossfun","page":"Candidate Utilities","title":"NaiveGAflux.lossfun","text":"lossfun(c::AbstractCandidate; [default])\n\nReturn the loss function of candidate c if c has a lossfunction, default (which defaults to nothing) otherwise.\n\n\n\n\n\n","category":"function"},{"location":"reference/candidate/#NaiveGAflux.BatchSizeIteratorMap","page":"Candidate Utilities","title":"NaiveGAflux.BatchSizeIteratorMap","text":"BatchSizeIteratorMap{F} <: AbstractIteratorMap \nBatchSizeIteratorMap(limitfun, trainbatchsize, validationbatchsize, model)\n\nAbstractIteratorMap which sets the batch size of training and validation iterators to trainbatchsize and validationbatchsize respectively. limitfun is used to try to ensure that batch sizes are small enough so that training and validating model does not risk an out of memory error. Use batchsizeselection to create an appropriate limitfun.\n\nExamples\n\njulia> using NaiveGAflux, Flux\n\njulia> import NaiveGAflux: maptrain, mapvalidation # needed for examples only\n\n\njulia> graph =  let \n                    v0 = conv2dinputvertex(\"v0\", 3);\n                    v1 = fluxvertex(\"v1\", Conv((3,3), nout(v0) => 8), v0);\n                    CompGraph(v0, v1);\n                end;\n\njulia> bsim = BatchSizeIteratorMap(4, 8, batchsizeselection((32,32,3)), graph);\n\njulia> collect(maptrain(bsim, (1:20,)))\n5-element Vector{Vector{Int64}}:\n [1, 2, 3, 4]\n [5, 6, 7, 8]\n [9, 10, 11, 12]\n [13, 14, 15, 16]\n [17, 18, 19, 20]\n\njulia> collect(mapvalidation(bsim, (1:20,)))\n3-element Vector{Vector{Int64}}:\n [1, 2, 3, 4, 5, 6, 7, 8]\n [9, 10, 11, 12, 13, 14, 15, 16]\n [17, 18, 19, 20]\n\njulia> map(x -> Pair(x...), maptrain(bsim, ((1:20, 21:40),))) # Pair to make results a bit easier on the eyes\n5-element Vector{Pair{SubArray{Int64, 1, Vector{Int64}, Tuple{UnitRange{Int64}}, true}, SubArray{Int64, 1, Vector{Int64}, Tuple{UnitRange{Int64}}, true}}}:\n     [1, 2, 3, 4] => [21, 22, 23, 24]\n     [5, 6, 7, 8] => [25, 26, 27, 28]\n  [9, 10, 11, 12] => [29, 30, 31, 32]\n [13, 14, 15, 16] => [33, 34, 35, 36]\n [17, 18, 19, 20] => [37, 38, 39, 40]\n\njulia> map(x -> Pair(x...), maptrain(bsim, BatchIterator((1:20, 21:40),12))) # Pair to make results a bit easier on the eyes\n5-element Vector{Pair{SubArray{Int64, 1, Vector{Int64}, Tuple{UnitRange{Int64}}, true}, SubArray{Int64, 1, Vector{Int64}, Tuple{UnitRange{Int64}}, true}}}:\n     [1, 2, 3, 4] => [21, 22, 23, 24]\n     [5, 6, 7, 8] => [25, 26, 27, 28]\n  [9, 10, 11, 12] => [29, 30, 31, 32]\n [13, 14, 15, 16] => [33, 34, 35, 36]\n [17, 18, 19, 20] => [37, 38, 39, 40]\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#MutationOperationsAPI","page":"Mutation Operations","title":"Mutation Operations","text":"","category":"section"},{"location":"reference/mutation/#Core-Vertex-Mutation-Operations","page":"Mutation Operations","title":"Core Vertex Mutation Operations","text":"","category":"section"},{"location":"reference/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"NoutMutation\nAddVertexMutation\nRemoveVertexMutation\nAddEdgeMutation\nRemoveEdgeMutation\nKernelSizeMutation\nActivationFunctionMutation","category":"page"},{"location":"reference/mutation/#NaiveGAflux.NoutMutation","page":"Mutation Operations","title":"NaiveGAflux.NoutMutation","text":"NoutMutation <:AbstractMutation{AbstractVertex}\nNoutMutation(l1::Real,l2::Real, rng::AbstractRNG)\nNoutMutation(limit, rng::AbstractRNG=rng_default)\nNoutMutation(l1,l2)\n\nMutate the out size of a vertex or vector of vertices.\n\nSize is changed by x * nout(v) rounded away from from zero where x is drawn from U(minrel, maxrel) where  minrel and maxrel are l1 and l2 if l1 < l2 and l2 and l1 otherwise.\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#NaiveGAflux.AddVertexMutation","page":"Mutation Operations","title":"NaiveGAflux.AddVertexMutation","text":"AddVertexMutation <:AbstractMutation{AbstractVertex}\nAddVertexMutation(s::AbstractArchSpace, outselect::Function, WeightInit::AbstractWeightInit, rng::AbstractRNG)\nAddVertexMutation(s, outselect::Function=identity)\nAddVertexMutation(s, rng::AbstractRNG)\nAddVertexMutation(s, wi::AbstractWeightInit)\n\nInsert a vertex from the wrapped AbstractArchSpace s after a given vertex v.\n\nThe function outselect takes an AbstractVector{AbstractVertex} representing the output of v and returns an AbstractVector{AbstractVertex} which shall be reconnected to the vertex v' returned by s. Defaults to identity meaning all outputs of v are reconnected to v'.\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#NaiveGAflux.RemoveVertexMutation","page":"Mutation Operations","title":"NaiveGAflux.RemoveVertexMutation","text":"RemoveVertexMutation <:AbstractMutation{AbstractVertex}\nRemoveVertexMutation(s::RemoveStrategy)\nRemoveVertexMutation()\n\nRemove the given vertex v using the configured RemoveStrategy.\n\nDefault size align strategy is IncreaseSmaller -> DecreaseBigger -> AlignSizeBoth -> FailAlignSizeWarn -> FailAlignSizeRevert.\n\nDefault reconnect strategy is ConnectAll.\n\nNote: High likelyhood of large accuracy degradation after applying this mutation.\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#NaiveGAflux.AddEdgeMutation","page":"Mutation Operations","title":"NaiveGAflux.AddEdgeMutation","text":"AddEdgeMutation <: AbstractMutation{AbstractVertex}\nAddEdgeMutation(p; rng=rng_default, mergefun=default_mergefun(rng=rng), filtfun=no_shapechange, utilityfun=default_neuronselect)\nAddEdgeMutation(p::Probability; rng=rng_default, mergefun=default_mergefun(rng=rng), filtfun=no_shapechange, utilityfun=default_neuronselect)\n\nAdd an edge from a vertex vi to another vertex vo randomly selected from vs = filtfun(vi).\n\nHigher values of p will give more preference to earlier vertices of vs.\n\nIf vo is not capable of having multiple inputs (determined by singleinput(v) == true), vm = mergefun(voi) where voi is a randomly selected input to vo will be used instead of vo and vo will be added as the output of vm.\n\nWhen selecting neurons/outputs after any eventual size change the output of utilityfun(v) will be used to determine the utlity of each output in vertex v. Note that length(utilityfun(v)) == nout(v) must hold.\n\nNote: High likelyhood of large accuracy degradation after applying this mutation.\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#NaiveGAflux.RemoveEdgeMutation","page":"Mutation Operations","title":"NaiveGAflux.RemoveEdgeMutation","text":"RemoveEdgeMutation <: AbstractMutation{AbstractVertex}\nRemoveEdgeMutation(;utilityfun=default_neuronselect, rng=rng_default)\n\nRemove an edge from a vertex vi to another vertex vo randomly selected from outputs(vi).\n\nVertex vi must have more than one output and vertex vo must have more than one output for the edge to be removed. Otherwise no change is made.\n\nIf there are multiple edges between vi and vo no change will be made due to NaiveNASlib not being able to revert a failed operation in this case..\n\nWhen selecting neurons/outputs after any eventual size change the output of utilityfun(v) will be used to determine the utlity of each output in vertex v. Note that length(utilityfun(v)) == nout(v) must hold.\n\nNote: High likelyhood of large accuracy degradation after applying this mutation.\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#NaiveGAflux.KernelSizeMutation","page":"Mutation Operations","title":"NaiveGAflux.KernelSizeMutation","text":"KernelSizeMutation{N} <: AbstractMutation{AbstractVertex}\nKernelSizeMutation(Δsizespace::AbstractParSpace{N, Int}; maxsize, pad, rng)\nKernelSizeMutation2D(absΔ::Integer;maxsize, pad, rng)\nKernelSizeMutation(absΔ::Integer...;maxsize, pad, rng)\n\nMutate the size of filter kernels of convolutional layers.\n\nNote: High likelyhood of large accuracy degradation after applying this mutation.\n\nKernelSizeMutation2D is a convenience constructor for KernelSizeMutation(absΔ, absΔ;...).\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#NaiveGAflux.ActivationFunctionMutation","page":"Mutation Operations","title":"NaiveGAflux.ActivationFunctionMutation","text":"ActivationFunctionMutation{T,R} <: AbstractMutation{AbstractVertex} where {T <: AbstractParSpace{1}, R <: AbstractRNG}\nActivationFunctionMutation(actspace::AbstractParSpace{1}, rng::AbstractRNG)\nActivationFunctionMutation(acts...;rng=rng_default)\nActivationFunctionMutation(acts::AbstractVector;rng=rng_default)\n\nMutate the activation function of layers which have an activation function.\n\nNote: High likelyhood of large accuracy degradation after applying this mutation.\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#Core-Optimizer-Mutation-Operations","page":"Mutation Operations","title":"Core Optimizer Mutation Operations","text":"","category":"section"},{"location":"reference/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"OptimizerMutation\nLearningRateMutation\nAddOptimizerMutation","category":"page"},{"location":"reference/mutation/#NaiveGAflux.OptimizerMutation","page":"Mutation Operations","title":"NaiveGAflux.OptimizerMutation","text":"struct OptimizerMutation{F} <: AbstractMutation{FluxOptimizer}\nOptimizerMutation(optfun)\nOptimizerMutation(os::Union{Tuple, <:AbstractArray})\n\nMutatates optimizers not wrapped in ShieldedOpt through optfun.\n\nInvoked recursively for Flux.Optimisers.\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#NaiveGAflux.LearningRateMutation","page":"Mutation Operations","title":"NaiveGAflux.LearningRateMutation","text":"LearningRateMutation(rng=rng_default)\n\nReturn an OptimizerMutation which mutates the learning rate of optimizers.\n\n\n\n\n\n","category":"function"},{"location":"reference/mutation/#NaiveGAflux.AddOptimizerMutation","page":"Mutation Operations","title":"NaiveGAflux.AddOptimizerMutation","text":"AddOptimizerMutation{F} <: AbstractMutation{FluxOptimizer}\n\nAdds optimizer generated by optgen(os) to the set of optimizers where os is the existing set.\n\nAn attempt to merge optimizers of the same type is made using mergeopts.\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#Wrapping-Mutation-Operations","page":"Mutation Operations","title":"Wrapping Mutation Operations","text":"","category":"section"},{"location":"reference/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"VertexMutation\nMutationProbability\nWeightedMutationProbability\nHighUtilityMutationProbability\nLowUtilityMutationProbability\nMutationChain\nLogMutation\nMutationFilter","category":"page"},{"location":"reference/mutation/#NaiveGAflux.VertexMutation","page":"Mutation Operations","title":"NaiveGAflux.VertexMutation","text":"VertexMutation <: DecoratingMutation{CompGraph}\nVertexMutation(m::AbstractMutation{AbstractVertex}, s::AbstractVertexSelection)\nVertexMutation(m::AbstractMutation{AbstractVertex})\n\nApplies a wrapped AbstractMutation{AbstractVertex} to each selected vertex in a CompGraph.\n\nVertices to select is determined by the configured AbstractVertexSelection.\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#NaiveGAflux.MutationProbability","page":"Mutation Operations","title":"NaiveGAflux.MutationProbability","text":"MutationProbability{T} <: DecoratingMutation{T}\nMutationProbability(m::AbstractMutation{T}, p::Probability)\nMutationProbability(m::AbstractMutation{T}, p::Number)\n\nApplies m with probability p.\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#NaiveGAflux.WeightedMutationProbability","page":"Mutation Operations","title":"NaiveGAflux.WeightedMutationProbability","text":"WeightedMutationProbability{T,F} <: DecoratingMutation{T}\nWeightedMutationProbability(m::AbstractMutation::T, pfun::F)\n\nApplies m to an entity e with a probability pfun(e).\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#NaiveGAflux.HighUtilityMutationProbability","page":"Mutation Operations","title":"NaiveGAflux.HighUtilityMutationProbability","text":"HighUtilityMutationProbability(m::AbstractMutation{T}, pbase::Real, rng=rng_default; spread=0.5)\n\nReturn a WeightedMutationProbability which applies m to vertices with an (approximately) average probability of pbase and where high neuronutility compared to other vertices in same graph means higher probability.\n\nParameter spread can be used to control how much the difference in probability is between high and low utlity. High spread means high difference while low spread means low difference.\n\n\n\n\n\n","category":"function"},{"location":"reference/mutation/#NaiveGAflux.LowUtilityMutationProbability","page":"Mutation Operations","title":"NaiveGAflux.LowUtilityMutationProbability","text":"LowUtilityMutationProbability(m::AbstractMutation{T}, pbase::Real, rng=rng_default; spread=2)\n\nReturn a WeightedMutationProbability which applies m to vertices with an (approximately) average probability of pbase and where low neuronutility compared to other vertices in same graph means higher probability.\n\nParameter spread can be used to control how much the difference in probability is between high and low utlity. High spread means high difference while low spread means low difference.\n\n\n\n\n\n","category":"function"},{"location":"reference/mutation/#NaiveGAflux.MutationChain","page":"Mutation Operations","title":"NaiveGAflux.MutationChain","text":"MutationChain{T} <: DecoratingMutation{T}\nMutationChain(m::AbstractMutation{T}...)\n\nChains multiple AbstractMutation{T}s after each other.\n\nInput entities will be mutated by the first AbstractMutation{T} in the chain and the output will be fed into the next AbstractMutation{T} in the chain and so on. The output from the last AbstractMutation{T} is returned.\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#NaiveGAflux.LogMutation","page":"Mutation Operations","title":"NaiveGAflux.LogMutation","text":"LogMutation{T} < :DecoratingMutation{T}\nLogMutation(strfun, m::AbstractMutation{T}; level = Logging.Info, nextlogfun=e -> PrefixLogger(\"   \"))\nLogMutation(strfun, level::LogLevel, nextlogfun, m::AbstractMutation{T})\n\nLogs all mutation operations.\n\nArgument strfun maps the mutated entity to the logged string.\n\nCalling nextlogfun(e) where e is the entity to mutate produces an AbstractLogger which will be used when applying m(e).\n\nBy default, this is used to add a level of indentation to subsequent logging calls which makes logs of hierarchical mutations (e.g. mutate a CompGraph by applying mutations to some of its vertices) easier to read. Set nextlogfun = e -> current_logger() to remove this behaviour.\n\n\n\n\n\n","category":"type"},{"location":"reference/mutation/#NaiveGAflux.MutationFilter","page":"Mutation Operations","title":"NaiveGAflux.MutationFilter","text":"MutationFilter{T} <: DecoratingMutation{T}\nMutationFilter(predicate, m)\n\nApplies mutation m only for entities e for which predicate(e) returns true.\n\n\n\n\n\n","category":"type"},{"location":"reference/batchsize/#BatchSizeUtilsAPI","page":"Batch Size Utilities","title":"Batch Size Utilities","text":"","category":"section"},{"location":"reference/batchsize/","page":"Batch Size Utilities","title":"Batch Size Utilities","text":"batchsizeselection\nBatchSizeSelectionWithDefaultInShape\nBatchSizeSelectionScaled\nBatchSizeSelectionFromAlternatives\nBatchSizeSelectionMaxSize","category":"page"},{"location":"reference/batchsize/#NaiveGAflux.batchsizeselection","page":"Batch Size Utilities","title":"NaiveGAflux.batchsizeselection","text":"batchsizeselection(inshape_nobatch::Tuple; maxmemutil=0.7, uppersize=nothing, alternatives=nothing, batchsizefun=limit_maxbatchsize)\n\nReturn a batch size selection callable which may be used to select an appropriate batch size when given a model and  a suggested batch size.\n\ninshape_nobatch is the size of the input without the batch dimension (e.g. 3 values for images) to be assumed. See BatchSizeSelectionWithDefaultInShape\n\nbatchsizefun is a function with the following signature:\n\nbatchsizefun(model, batchsize; inshape_nobatch, availablebytes)\n\nIt returns the largest batch size not larger than batchsize which can be used for model without using more than availablebytes bytes of memory. The type of batchsize may be used to e.g. determine if one shall account for backwards pass (if typeof(batchsize) === TrainBatchSize) or not (if typeof(batchsize) == ValidationBatchSize).\n\nmaxmemutil is the maximum memory utilization which typically need to be < 1 to account for inaccuracies in the estimation. See BatchSizeSelectionScaled\n\nIf uppersize is not nothing the maximum possible batchsize smaller or equal to uppersize will be used. See BatchSizeSelectionMaxSize\n\nIf alternatives is not nothing, the returned batchsize will be quantized to the closest matching size in alternatives which is not bigger than the unquantized batch size. See BatchSizeSelectionFromAlternatives.\n\nExamples\n\njulia> using NaiveGAflux, Flux\n\njulia> import NaiveGAflux: TrainBatchSize, ValidationBatchSize # Needed only for examples\n\n\njulia> graph =  let \n                    v0 = conv2dinputvertex(\"v0\", 3);\n                    v1 = fluxvertex(\"v1\", Conv((3,3), nout(v0) => 8), v0);\n                    CompGraph(v0, v1);\n                end;\n\njulia> bs = batchsizeselection((32,32,3));\n\njulia> bs(graph, TrainBatchSize(128); availablebytes = 10_000_000) # availablebytes supplied for doctest reasons\n84\n\njulia> bs(graph, ValidationBatchSize(128); availablebytes = 10_000_000)\n128\n\njulia> bs = batchsizeselection((32,32,3); maxmemutil=0.1);\n\njulia> bs(graph, TrainBatchSize(128); availablebytes = 10_000_000)\n12\n\njulia> bs(graph, ValidationBatchSize(128); availablebytes = 10_000_000)\n24\n\njulia> bs = batchsizeselection((32,32,3); uppersize=1024);\n\njulia> bs(graph, TrainBatchSize(128); availablebytes = 10_000_000)\n84\n\njulia> bs(graph, ValidationBatchSize(128); availablebytes = 10_000_000)\n170\n\njulia> bs = batchsizeselection((32,32,3); uppersize=1024, alternatives = 2 .^ (0:10));\n\njulia> bs(graph, TrainBatchSize(128); availablebytes = 10_000_000)\n64\n\njulia> bs(graph, ValidationBatchSize(128); availablebytes = 10_000_000)\n128\n\n\n\n\n\n","category":"function"},{"location":"reference/batchsize/#NaiveGAflux.BatchSizeSelectionWithDefaultInShape","page":"Batch Size Utilities","title":"NaiveGAflux.BatchSizeSelectionWithDefaultInShape","text":"BatchSizeSelectionWithDefaultInShape{T, F}\nBatchSizeSelectionWithDefaultInShape(default_inshape)\nBatchSizeSelectionWithDefaultInShape(default_inshape, batchsizefun)\n\nBatch size selection with a default assumed inshape used for estimating valid batch sizes.\n\nbatchsizefun is a function with the following signature:\n\nbatchsizefun(model, batchsize; inshape_nobatch, availablebytes)\n\nIt returns the largest batch size not larger than batchsize which can be used for model without using more than availablebytes bytes of memory. The type of batchsize may be used to e.g. determine if one shall account for backwards pass (if typeof(batchsize) === TrainBatchSize) or not (if typeof(batchsize) == ValidationBatchSize).\n\nReturns the result of batchsizefun with default value of inshape_nobatch = default_inshape when called as a function with valid inputs to batchsizefun.\n\nComposable with other batch size selection types which may be used as batchsizefun. See examples.\n\nExamples\n\njulia> using NaiveGAflux, Flux\n\njulia> import NaiveGAflux: TrainBatchSize, ValidationBatchSize # Needed only for examples\n\n\njulia> graph =  let \n                    v0 = conv2dinputvertex(\"v0\", 3);\n                    v1 = fluxvertex(\"v1\", Conv((3,3), nout(v0) => 8), v0);\n                    CompGraph(v0, v1);\n                end;\n\njulia> bs = BatchSizeSelectionWithDefaultInShape((32,32,3));\n\njulia> bs(graph, TrainBatchSize(512); availablebytes = 10_000_000) # availablebytes supplied for doctest reasons\n120\n\njulia> bs(graph, TrainBatchSize(512); availablebytes = 1000_000_000)\n512\n\njulia> sbs = BatchSizeSelectionWithDefaultInShape((32,32,3), BatchSizeSelectionScaled(0.5));\n\njulia> sbs(graph, TrainBatchSize(512); availablebytes = 10_000_000)\n60\n\njulia> sbs(graph, TrainBatchSize(512); availablebytes = 1000_000_000)\n512\n\njulia> bs(graph, ValidationBatchSize(512); availablebytes=10_000_000)\n243\n\n\n\n\n\n\n","category":"type"},{"location":"reference/batchsize/#NaiveGAflux.BatchSizeSelectionScaled","page":"Batch Size Utilities","title":"NaiveGAflux.BatchSizeSelectionScaled","text":"BatchSizeSelectionScaled{F}\nBatchSizeSelectionScaled(scale)\nBatchSizeSelectionScaled(scale, batchsizefun)\n\nBatch size selection with a margin applied when estimating valid batch sizes.\n\nbatchsizefun is a function with the following signature:\n\nbatchsizefun(model, batchsize; inshape_nobatch, availablebytes)\n\nIt returns the largest batch size not larger than batchsize which can be used for model without using more than availablebytes bytes of memory. The type of batchsize may be used to e.g. determine if one shall account for backwards pass (if typeof(batchsize) === TrainBatchSize) or not (if typeof(batchsize) == ValidationBatchSize).\n\nReturns the result of batchsizefun with default value of availablebytes = floor(scale * availablebytes) when called as a function with valid inputs to batchsizefun.\n\nComposable with other batch size selection types which may be used as batchsizefun. See examples.\n\nExamples\n\njulia> using NaiveGAflux, Flux\n\njulia> import NaiveGAflux: TrainBatchSize, ValidationBatchSize # Needed only for examples\n\n\njulia> graph =  let \n                    v0 = conv2dinputvertex(\"v0\", 3);\n                    v1 = fluxvertex(\"v1\", Conv((3,3), nout(v0) => 8), v0);\n                    CompGraph(v0, v1);\n                end;\n\njulia> bs = BatchSizeSelectionScaled(0.5);\n\njulia> bs(graph, TrainBatchSize(512); inshape_nobatch=(32,32,3), availablebytes = 10_000_000) # availablebytes supplied for doctest reasons\n60\n\njulia> bs(graph, TrainBatchSize(512); inshape_nobatch=(32,32,3), availablebytes = 1000_000_000)\n512\n\njulia> sbs = BatchSizeSelectionScaled(0.5, BatchSizeSelectionWithDefaultInShape((32,32,3)));\n\njulia> sbs(graph, TrainBatchSize(512); availablebytes = 10_000_000)\n60\n\njulia> sbs(graph, TrainBatchSize(512); availablebytes = 1000_000_000)\n512\n\njulia> bs(graph, ValidationBatchSize(512); inshape_nobatch=(32,32,3), availablebytes=10_000_000)\n121\n\n\n\n\n\n\n","category":"type"},{"location":"reference/batchsize/#NaiveGAflux.BatchSizeSelectionFromAlternatives","page":"Batch Size Utilities","title":"NaiveGAflux.BatchSizeSelectionFromAlternatives","text":"BatchSizeSelectionFromAlternatives{T, F}\nBatchSizeSelectionFromAlternatives(alts)\nBatchSizeSelectionFromAlternatives(alts, batchsizefun)\n\nBatch size selection from a set of available alternatives. Useful for iterators which need to be pre-loaded with batch size, for example the iterators in this package.\n\nbatchsizefun is a function with the following signature:\n\nbatchsizefun(model, batchsize; inshape_nobatch, availablebytes)\n\nIt returns the largest batch size not larger than batchsize which can be used for model without using more than availablebytes bytes of memory. The type of batchsize may be used to e.g. determine if one shall account for backwards pass (if typeof(batchsize) === TrainBatchSize) or not (if typeof(batchsize) == ValidationBatchSize).\n\nReturns the largest number in alts smaller than the result of batchsizefun when called as a function with valid inputs to batchsizefun.\n\nComposable with other batch size selection types which may be used as batchsizefun. See examples.\n\nExamples\n\njulia> using NaiveGAflux, Flux\n\njulia> import NaiveGAflux: TrainBatchSize, ValidationBatchSize # Needed only for examples\n\n\njulia> graph =  let \n                    v0 = conv2dinputvertex(\"v0\", 3);\n                    v1 = fluxvertex(\"v1\", Conv((3,3), nout(v0) => 8), v0);\n                    CompGraph(v0, v1);\n                end;\n\njulia> bs = BatchSizeSelectionFromAlternatives(2 .^ (0:10));\n\njulia> bs(graph, TrainBatchSize(512); inshape_nobatch=(32,32,3), availablebytes = 10_000_000) # availablebytes supplied for doctest reasons\n64\n\njulia> bs(graph, TrainBatchSize(512); inshape_nobatch=(32,32,3), availablebytes = 1000_000_000)\n512\n\njulia> sbs = BatchSizeSelectionFromAlternatives(2 .^ (0:10), BatchSizeSelectionScaled(0.5));\n\njulia> sbs(graph, TrainBatchSize(512); inshape_nobatch=(32,32,3), availablebytes = 10_000_000)\n32\n\njulia> sbs(graph, TrainBatchSize(512); inshape_nobatch=(32,32,3), availablebytes = 1000_000_000)\n512\n\njulia> bs(graph, ValidationBatchSize(512); inshape_nobatch=(32,32,3), availablebytes=10_000_000)\n128\n\n\n\n\n\n\n","category":"type"},{"location":"reference/batchsize/#NaiveGAflux.BatchSizeSelectionMaxSize","page":"Batch Size Utilities","title":"NaiveGAflux.BatchSizeSelectionMaxSize","text":"BatchSizeSelectionMaxSize{F}\nBatchSizeSelectionMaxSize(uppersize) \nBatchSizeSelectionMaxSize(uppersize, batchsizefun)\n\nBatch size selection which always try to select uppersize. Basically the strategy to select the largest batchsize which fits in memory.\n\nbatchsizefun is a function with the following signature:\n\nbatchsizefun(model, batchsize; inshape_nobatch, availablebytes)\n\nIt returns the largest batch size not larger than batchsize which can be used for model without using more than availablebytes bytes of memory. The type of batchsize may be used to e.g. determine if one shall account for backwards pass (if typeof(batchsize) === TrainBatchSize) or not (if typeof(batchsize) == ValidationBatchSize).\n\nReturns the result of batchsizefun but with the batchsize as uppersize of the same type as batchsize (i.e. to differentiate between train size and validation size).\n\nComposable with other batch size selection types which may be used as batchsizefun. See examples.\n\nExamples\n\njulia> using NaiveGAflux, Flux\n\njulia> import NaiveGAflux: TrainBatchSize, ValidationBatchSize # Needed only for examples\n\n\njulia> graph =  let \n                    v0 = conv2dinputvertex(\"v0\", 3);\n                    v1 = fluxvertex(\"v1\", Conv((3,3), nout(v0) => 8), v0);\n                    CompGraph(v0, v1);\n                end;\n\njulia> bs = BatchSizeSelectionMaxSize(1024);\n\njulia> bs(graph, TrainBatchSize(512); inshape_nobatch=(32,32,3), availablebytes = 10_000_000) # availablebytes supplied for doctest reasons\n120\n\njulia> bs(graph, TrainBatchSize(512); inshape_nobatch=(32,32,3), availablebytes = 1000_000_000)\n1024\n\njulia> sbs = BatchSizeSelectionMaxSize(1024, BatchSizeSelectionScaled(0.5));\n\njulia> sbs(graph, TrainBatchSize(512); inshape_nobatch=(32,32,3), availablebytes = 10_000_000)\n60\n\njulia> sbs(graph, TrainBatchSize(512); inshape_nobatch=(32,32,3), availablebytes = 1000_000_000)\n1024\n\njulia> bs(graph, ValidationBatchSize(512); inshape_nobatch=(32,32,3), availablebytes=10_000_000)\n243\n\n\n\n\n\n\n","category":"type"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"EditURL = \"https://github.com/DrChainsaw/NaiveGAflux.jl/blob/master/test/examples/searchspace.jl\"","category":"page"},{"location":"examples/searchspace/#Search-Spaces","page":"Search Spaces","title":"Search Spaces","text":"","category":"section"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"The search space is a set of possible architectures which the search policy may use to create initial candidates or to extend existing candidates. Search spaces are constructed from simple components which can be combined in multiple ways, giving a lot of flexibility.","category":"page"},{"location":"examples/searchspace/#Simple-Parameter-Spaces","page":"Search Spaces","title":"Simple Parameter Spaces","text":"","category":"section"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"The most fundamental building block of any search space if the ParSpace:","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"ps1d = ParSpace([2,4,6,10])","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Draw from the search space.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"@test ps1d() == 6\n@test ps1d() == 10","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Possible to supply a random number generator.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"@test ps1d(MersenneTwister(0)) == 4","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"ParSpaces can be of any dimension and type.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"ps2d = ParSpace([\"1\",\"2\",\"3\"], [\"4\",\"5\",\"6\",\"7\"])\n\n@test typeof(ps1d) == ParSpace{1, Int}\n@test typeof(ps2d) == ParSpace{2, String}\n\n@test ps2d() == (\"1\", \"4\")","category":"page"},{"location":"examples/searchspace/#Layer-Search-Spaces","page":"Search Spaces","title":"Layer Search Spaces","text":"","category":"section"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"A LayerSpace is a search space of configurations of a single Flux layer. It is worth noting that NaiveGAflux separates search spaces for creation of new layers from modification of existing layers. A layer drawn from a LayerSpace can thus be mutated into a new layer which is not part of the search space it was drawn from.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Lets look at how to create a search space for 2D convolutions:","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"cs = ConvSpace{2}(outsizes=4:32, activations=[relu, elu, selu], kernelsizes=3:9)\n\ninputsize = 16\nconvlayer = cs(inputsize)\n\n@test string(convlayer) == \"Conv((8, 3), 16 => 22, relu, pad=(4, 3, 1, 1))\"","category":"page"},{"location":"examples/searchspace/#Architecture-Search-Spaces","page":"Search Spaces","title":"Architecture Search Spaces","text":"","category":"section"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"An architecture space is a search space over vertices in a computation graph, including how they are connected. Just as with Layer Search Spaces, the architecture search spaces are separate from modifications of graphs, meaning that an architecture drawn from a search space may be mutated into an architecture which is not part of the searh space it was drawn from.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Lets look at an example of a search space of large image classifiers:","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"VertexSpace creates a MutableVertex of layers generated by the wrapped search space.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"cs = VertexSpace(ConvSpace{2}(outsizes=8:256, activations=[identity, relu, elu], kernelsizes=3:5))\nbs = VertexSpace(BatchNormSpace([identity, relu]))","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Block of Conv->BatchNorm and BatchNorm->Conv respectively. Need to make sure there is always at least one SizeAbsorb layer to make fork and res below play nice.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"csbs = ArchSpaceChain(cs ,bs)\nbscs = ArchSpaceChain(bs, cs)","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Randomly generates either Conv, Conv->BatchNorm or BatchNorm->Conv:","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"cblock = ArchSpace(ParSpace1D(cs, csbs, bscs))","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Generates between 1 and 5 (independent) samples from csbs in a sequence.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"rep = RepeatArchSpace(cblock, 1:5)","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Generates between 2 and 4 parallel paths joined by concatenation (inception like-blocks) drawn from rep.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"fork = ForkArchSpace(rep, 2:4)","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Generates a residual connection around what is generated by rep.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"res = ResidualArchSpace(rep)","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"... and a residual fork.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"resfork = ResidualArchSpace(fork)","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Pick one of the above randomly...","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"repforkres = ArchSpace(ParSpace1D(rep, fork, res, resfork))","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"...1 to 3 times.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"blocks = RepeatArchSpace(repforkres, 1:3)","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"End each block with subsamping through maxpooling.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"ms = VertexSpace(PoolSpace{2}(windowsizes=2, strides=2, poolfuns=MaxPool))\nreduction = ArchSpaceChain(blocks, ms)","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"And lets do 2 to 4 reductions.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"featureextract = RepeatArchSpace(reduction, 2:4)","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Adds 1 to 3 dense layers as outputs.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"dense = VertexSpace(DenseSpace(16:512, [relu, selu]))\ndrep = RepeatArchSpace(dense, 0:2)","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Last layer has fixed output size (number of labels).","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"dout=VertexSpace(Shielded(), DenseSpace(10, identity))\noutput = ArchSpaceChain(drep, dout)","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Aaaand lets glue it together: Feature extracting Conv/BatchNorm layers -> global pooling -> dense layers.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"archspace = ArchSpaceChain(featureextract, GlobalPoolSpace(), output)","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Input is 3 channel image.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"samplemodel(invertex=conv2dinputvertex(\"input\", 3)) = CompGraph(invertex, archspace(invertex))","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"Sample one architecture from the search space.","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"graph1 = samplemodel()\n@test nvertices(graph1) == 79","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"And one more...","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"graph2 = samplemodel()\n@test nvertices(graph2) == 128","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"","category":"page"},{"location":"examples/searchspace/","page":"Search Spaces","title":"Search Spaces","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"EditURL = \"https://github.com/DrChainsaw/NaiveGAflux.jl/blob/master/test/examples/crossover.jl\"","category":"page"},{"location":"examples/crossover/#Crossover-Operations","page":"Crossover Operations","title":"Crossover Operations","text":"","category":"section"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"Crossover is the way two candidates are combined to create new candidates. In NaiveGAflux crossover always maps two candidates into two new candidates. Just as for mutation, NaiveGAflux does this while preserving (to whatever extent possible) the parameters and alignment between layers of the combined models.","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"Crossover operations might not seem to make much sense when using parameter inheritance (i.e the concept that children retain the parameters of their parents). Randomly combining layers from two very different models will most likely not result in a well performing model. There are however a few potentially redeeming effects:","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"Early in the evolution process parameters are not yet well fitted and inheriting parameters is not worse than random initialization\nA mature population on the other hand will consist mostly of models which are close relatives and therefore have somewhat similar weights.","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"Whether these effects actually make crossover a genuinely useful operation when evolving neural networks is not yet proven though. For now it is perhaps best to view the crossover operations as being provided mostly for the sake of completeness.","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"The following basic crossover operations are currently supported:","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"Swap segments between two models using CrossoverSwap.\nSwap optimizers between two candidates using OptimizerCrossover.\nSwap learning rate between two candidates using LearningRateCrossover.","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"Most of the mutation utilities also work with crossover operations. Here are a few examples:","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"Start by creating a model to play with.","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"invertex = denseinputvertex(\"A.in\", 3)\nlayer1 = fluxvertex(\"A.l1\", Dense(nout(invertex), 4), invertex; layerfun=ActivationContribution)\nlayer2 = fluxvertex(\"A.l2\", Dense(nout(layer1), 5), layer1; layerfun=ActivationContribution)\nlayer3 = fluxvertex(\"A.l3\", Dense(nout(layer2), 3), layer2; layerfun=ActivationContribution)\nlayer4 = fluxvertex(\"A.l4\", Dense(nout(layer3), 2), layer3; layerfun=ActivationContribution)\nmodelA = CompGraph(invertex, layer4)","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"Create an exact copy to show how parameter alignment is preserved. Prefix names with B so we can show that something actually happened.","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"import Functors\nmodelB = Functors.fmap(x -> x isa String ? replace(x, r\"^A.\\.*\" => \"B.\") : x, modelA)\n\nindata = reshape(collect(Float32, 1:3*2), 3,2)\n@test modelA(indata) == modelB(indata)\n\n@test name.(vertices(modelA)) == [\"A.in\", \"A.l1\", \"A.l2\", \"A.l3\", \"A.l4\"]\n@test name.(vertices(modelB)) == [\"B.in\", \"B.l1\", \"B.l2\", \"B.l3\", \"B.l4\"]","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"CrossoverSwap takes ones vertex from each graph as input and swaps a random segment from each graph. By default it tries to make segments as similar as possible","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"swapsame = CrossoverSwap()\n\nswapA = vertices(modelA)[4]\nswapB = vertices(modelB)[4]\nnewA, newB = swapsame((swapA, swapB))","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"It returns vertices of a new graph to be compatible with mutation utilities. Parent models are not modified.","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"@test newA ∉ vertices(modelA)\n@test newB ∉ vertices(modelB)","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"The function regraph is an internal utility which should not be needed in normal use cases, but here we use it to make comparison easier.","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"modelAnew = NaiveGAflux.regraph(newA)\nmodelBnew = NaiveGAflux.regraph(newB)\n\n@test name.(vertices(modelAnew)) == [\"A.in\", \"A.l1\", \"B.l2\", \"B.l3\", \"A.l4\"]\n@test name.(vertices(modelBnew)) == [\"B.in\", \"B.l1\", \"A.l2\", \"A.l3\", \"B.l4\"]\n\n@test modelA(indata) == modelB(indata) == modelAnew(indata) == modelBnew(indata)","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"Deviation parameter will randomly make segments unequal.","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"swapdeviation = CrossoverSwap(0.5)\nmodelAnew2, modelBnew2 = NaiveGAflux.regraph.(swapdeviation((swapA, swapB)))\n\n@test name.(vertices(modelAnew2)) == [\"A.in\", \"A.l1\", \"A.l2\", \"B.l1\", \"B.l2\", \"B.l3\", \"A.l4\"]\n@test name.(vertices(modelBnew2)) == [\"B.in\", \"A.l3\", \"B.l4\"]","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"VertexCrossover applies the wrapped crossover operation to all vertices in a CompGraph and is the main API for doing crossover. It in addtion, it selects compatible pairs for us (i.e swapA and swapB above). It also takes an optional deviation parameter which is used when pairing.","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"crossoverall = VertexCrossover(swapdeviation, 0.5)\n\nmodelAnew3, modelBnew3 = crossoverall((modelA, modelB))","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"I guess things got swapped back and forth so many times not much changed in the end.","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"@test name.(vertices(modelAnew3)) == [\"A.in\", \"A.l2\", \"A.l4\"]\n@test name.(vertices(modelBnew3)) ==  [\"B.in\", \"B.l3\", \"B.l1\", \"B.l2\", \"A.l1\", \"A.l3\", \"B.l4\"]","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"As advertised above, crossovers interop with most mutation utilities, just remember that input is a tuple for things which require a callback. Perform the swapping operation with a 30% probability for each valid vertex pair and log which vertices are being swapped.","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"crossoversome = VertexCrossover(\n                    MutationProbability(\n                        LogMutation(\n                            ((v1,v2),) -> \"Swap $(name(v1)) and $(name(v2))\",\n                            swapdeviation),\n                    0.3)\n                )\n\n@test_logs( (:info, \"Swap A.l1 and B.l1\"),\n            (:info, \"Swap A.l2 and B.l2\"),\n            crossoversome((modelA, modelB)))","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"","category":"page"},{"location":"examples/crossover/","page":"Crossover Operations","title":"Crossover Operations","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"EditURL = \"https://github.com/DrChainsaw/NaiveGAflux.jl/blob/master/test/examples/mutation.jl\"","category":"page"},{"location":"examples/mutation/#Mutation-Operations","page":"Mutation Operations","title":"Mutation Operations","text":"","category":"section"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"Mutation is the way one candidate is transformed to a slightly different candidate. NaiveGAflux supports doing this while preserving parameters and alignment between layers, thus reducing the impact of mutating an already trained candidate.","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"The following basic mutation operations are currently supported:","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"Change the output size of vertices using NoutMutation.\nRemove vertices using RemoveVertexMutation.\nAdd vertices using AddVertexMutation.\nRemove edges between vertices using RemoveEdgeMutation.\nAdd edges between vertices using AddEdgeMutation.\nMutation of kernel size for conv layers using KernelSizeMutation.\nChange of activation function using ActivationFunctionMutation.\nChange the type of optimizer using OptimizerMutation.\nAdd an optimizer using AddOptimizerMutation.","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"Mutation operations are exported as structs rather than functions since they are designed to be composed with more generic utilities. Here are a few examples:","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"Start with a simple model to mutate.","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"invertex = denseinputvertex(\"in\", 3)\nlayer1 = fluxvertex(Dense(nout(invertex), 4), invertex)\nlayer2 = fluxvertex(Dense(nout(layer1), 5), layer1)\ngraph = CompGraph(invertex, layer2)","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"Create an NoutMutation to mutate it.","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"mutation = NoutMutation(-0.5, 0.5)\n\n@test nout(layer2) == 5\n\nmutation(layer2)\n\n@test nout(layer2) == 7","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"VertexMutation applies the wrapped mutation to all vertices in a CompGraph","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"mutation = VertexMutation(mutation)\n\n@test nout.(vertices(graph)) == [3,4,7]\n\nmutation(graph)\n\n@test nout.(vertices(graph)) == [3,6,10]","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"Input vertex is never mutated, but the other two changed. Use the MutationShield trait to protect otherwise mutable vertices from mutation.","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"outlayer = fluxvertex(Dense(nout(layer2), 10), layer2, traitfun = MutationShield)\ngraph = CompGraph(invertex, outlayer)\n\nmutation(graph)\n\n@test nout.(vertices(graph)) == [3,9,6,10]","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"In most cases it makes sense to mutate with a certain probability.","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"mutation = VertexMutation(MutationProbability(NoutMutation(-0.5, 0.5), 0.5))\n\nmutation(graph)\n\n@test nout.(vertices(graph)) == [3,9,3,10]","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"Or just chose to either mutate the whole graph or don't do anything.","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"mutation = MutationProbability(VertexMutation(NoutMutation(-0.5, 0.5)), 0.98)\n\nmutation(graph)\n\n@test nout.(vertices(graph)) == [3,10,2,10]\n@test size(graph(ones(3,1))) == (10, 1)","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"Mutation can also be conditioned:","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"mutation = VertexMutation(MutationFilter(v -> nout(v) < 10, RemoveVertexMutation()))\n\nmutation(graph)\n\n@test nout.(vertices(graph)) == [3,10,10]","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"When adding vertices it is probably a good idea to try to initialize them as identity mappings.","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"addmut = AddVertexMutation(VertexSpace(DenseSpace(5, identity)), IdentityWeightInit())","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"Chaining mutations is also useful:","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"noutmut = NoutMutation(-0.8, 0.8)\nmutation = VertexMutation(MutationChain(addmut, noutmut))\n\nmutation(graph)\n\n@test nout.(vertices(graph)) == [3,6,10,10]","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"","category":"page"},{"location":"examples/mutation/","page":"Mutation Operations","title":"Mutation Operations","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"EditURL = \"https://github.com/DrChainsaw/NaiveGAflux.jl/blob/master/test/examples/evolution.jl\"","category":"page"},{"location":"examples/evolution/#Evolution-Strategies","page":"Evolution Strategies","title":"Evolution Strategies","text":"","category":"section"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"Evolution strategies are the functions used to evolve the population in the genetic algorithm from one generation to the next. The following is performed by evolution strategies:","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"Select which candidates to use for the next generation\nProduce new candidates, e.g by mutating the selected candidates","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"Important to note about evolution strategies is that they generally expect candidates which can provide a precomputed fitness value, e.g. FittedCandidates. This is because the fitness value is used by things like sorting where it is not only impractical to recompute it, but is also might lead to undefined behaviour if it is not always the same. Use Population to get some help with computing fitness for all candidates before passing them on to evolution.","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"Note that there is no general requirement on an evolution strategy to return the same population size as it was given. It is also free to create completely new candidates without basing anything on any given candidate.","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"For controlled randomness in the examples.","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"struct FakeRng end\nBase.rand(::FakeRng) = 0.7","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"Dummy candidate for brevity.","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"struct Cand <: AbstractCandidate\n    fitness\nend\nNaiveGAflux.fitness(d::Cand) = d.fitness","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"EliteSelection selects the n best candidates.","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"elitesel = EliteSelection(2)\n@test evolve(elitesel, Cand.(1:10)) == Cand.([10, 9])","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"EvolveCandidates maps candidates to new candidates (e.g. through mutation).","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"evocands = EvolveCandidates(c -> Cand(fitness(c) + 0.1))\n@test evolve(evocands, Cand.(1:10)) == Cand.(1.1:10.1)","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"SusSelection selects candidates randomly using stochastic uniform sampling. Selected candidates will be forwarded to the wrapped evolution strategy before returned.","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"sussel = SusSelection(5, evocands, FakeRng())\n@test evolve(sussel, Cand.(1:10)) == Cand.([4.1, 6.1, 8.1, 9.1, 10.1])","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"CombinedEvolution combines the populations from several evolution strategies.","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"comb = CombinedEvolution(elitesel, sussel)\n@test evolve(comb, Cand.(1:10)) == Cand.(Any[10, 9, 4.1, 6.1, 8.1, 9.1, 10.1])","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"","category":"page"},{"location":"examples/evolution/","page":"Evolution Strategies","title":"Evolution Strategies","text":"This page was generated using Literate.jl.","category":"page"},{"location":"reference/fitness/#FitnessFunctionsAPI","page":"Fitness Functions","title":"Fitness Functions","text":"","category":"section"},{"location":"reference/fitness/","page":"Fitness Functions","title":"Fitness Functions","text":"fitness\nAccuracyFitness\nTrainThenFitness\nTrainAccuracyFitness\nSizeFitness\nTimeFitness\nLogFitness\nGpuFitness\nMapFitness\nEwmaFitness\nAggFitness","category":"page"},{"location":"reference/fitness/#NaiveGAflux.fitness","page":"Fitness Functions","title":"NaiveGAflux.fitness","text":"fitness(f::AbstractFitness, c::AbstractCandidate)\n\nCompute the fitness metric f for candidate c.\n\n\n\n\n\n","category":"function"},{"location":"reference/fitness/#NaiveGAflux.AccuracyFitness","page":"Fitness Functions","title":"NaiveGAflux.AccuracyFitness","text":"AccuracyFitness <: AbstractFitness\nAccuracyFitness(dataset)\n\nMeasure fitness as the accuracy on a dataset.\n\n\n\n\n\n","category":"type"},{"location":"reference/fitness/#NaiveGAflux.TrainThenFitness","page":"Fitness Functions","title":"NaiveGAflux.TrainThenFitness","text":"TrainThenFitness{I,L,O,F} <: AbstractFitness\nTrainThenFitness(;dataiter, defaultloss, defaultopt, fitstrat, invalidfitness=0.0)\n\nMeasure fitness using fitstrat after training the model using dataiter.\n\nLoss function and optimizer may be provided by the candidate if lossfun(c; defaultloss)  and opt(c; defaultopt) are implemented, otherwise defaultloss and defaultopt will  be used.\n\nThe data used for training is the result of itergeneration(dataiter, gen) where gen is the generation number. This defaults to returning dataiter but allows for more  complex iterators such as StatefulGenerationIter.\n\nIf the model loss is ever NaN or Inf the training will be stopped and invalidfitness will be returned without calculating the fitness using fitstrat. \n\nTip: Use TimedIterator to stop training of models which take too long to train.\n\n\n\n\n\n","category":"type"},{"location":"reference/fitness/#NaiveGAflux.TrainAccuracyFitness","page":"Fitness Functions","title":"NaiveGAflux.TrainAccuracyFitness","text":"struct TrainAccuracyFitness <: AbstractFitness\nTrainAccuracyFitness(;drop=0.5, kwargs...)\n\nMeasure fitness as the accuracy on the training data set. Beware of overfitting!\n\nParameter drop determines the fraction of examples to drop for fitness measurement. This mitigates the penalty for newly mutated candidates as the first part of the training examples are not used for fitness.\n\nOther keyword arguments are passed to TrainThenFitness constructor. Note that fitstrat should generally be left to default value.\n\nAdvantage vs AccuracyFitness is that one does not have to run through another data set. Disadvantage is that evolution will likely favour candidates which overfit.\n\n\n\n\n\n","category":"type"},{"location":"reference/fitness/#NaiveGAflux.SizeFitness","page":"Fitness Functions","title":"NaiveGAflux.SizeFitness","text":"SizeFitness <: AbstractFitness\nSizeFitness()\n\nMeasure fitness as the total number of parameters in the function to be evaluated.\n\n\n\n\n\n","category":"type"},{"location":"reference/fitness/#NaiveGAflux.TimeFitness","page":"Fitness Functions","title":"NaiveGAflux.TimeFitness","text":"TimeFitness{T} <: AbstractFitness\n\nMeasure fitness as time to evaluate a function.\n\nTime for first nskip evaluations will be discarded.\n\n\n\n\n\n","category":"type"},{"location":"reference/fitness/#NaiveGAflux.LogFitness","page":"Fitness Functions","title":"NaiveGAflux.LogFitness","text":"LogFitness{F, MF} <: AbstractFitness\nLogFitness(fitnesstrategy::AbstractFitness) = LogFitness(;fitnesstrategy)\nLogFitness(;currgen=0, candcnt=0, fitnesstrategy, msgfun=default_fitnessmsgfun)\n\nLogs the fitness of fitnessstrategy along with some candiate information.\n\n\n\n\n\n","category":"type"},{"location":"reference/fitness/#NaiveGAflux.GpuFitness","page":"Fitness Functions","title":"NaiveGAflux.GpuFitness","text":"GpuFitness{F} <: AbstractFitness\nGpuFitness(fitnesstrategy)\n\nMove candidates to gpu before calculating their fitness according to fitnesstrategy.\n\nCopies parameters back to the given candidate after fitness have been computed to ensure that updated parameters from training are used.  Assumes canidates have parameters on cpu for that step.\n\nNote that if no gpu is available this should be a noop.\n\n\n\n\n\n","category":"type"},{"location":"reference/fitness/#NaiveGAflux.MapFitness","page":"Fitness Functions","title":"NaiveGAflux.MapFitness","text":"MapFitness <: AbstractFitness\nMapFitness(mapping::Function, base::AbstractFitness)\n\nMaps fitness x from base to mapping(x).\n\n\n\n\n\n","category":"type"},{"location":"reference/fitness/#NaiveGAflux.EwmaFitness","page":"Fitness Functions","title":"NaiveGAflux.EwmaFitness","text":"EwmaFitness(base)\nEwmaFitness(α, base)\n\nComputes the exponentially weighted moving average of the fitness of base. Assumes that candidates previous fitness metric is available through fitness(cand).\n\nMain purpose is to mitigate the effects of fitness noise.\n\nSee https://github.com/DrChainsaw/NaiveGAExperiments/blob/master/fitnessnoise/experiments.ipynb for some hints as to why this might be needed.\n\n\n\n\n\n","category":"type"},{"location":"reference/fitness/#NaiveGAflux.AggFitness","page":"Fitness Functions","title":"NaiveGAflux.AggFitness","text":"AggFitness <: AbstractFitness\nAggFitness(aggfun::Function, fitnesses::AbstractFitness...)\n\nAggreagate fitness value from all fitnesses using aggfun\n\n\n\n\n\n","category":"type"},{"location":"reference/iterators/#IteratorsAPI","page":"Iterators","title":"Iterators","text":"","category":"section"},{"location":"reference/iterators/","page":"Iterators","title":"Iterators","text":"RepeatPartitionIterator\nSeedIterator\nGpuIterator\nBatchIterator\nTimedIterator\nStatefulGenerationIter","category":"page"},{"location":"reference/iterators/#NaiveGAflux.RepeatPartitionIterator","page":"Iterators","title":"NaiveGAflux.RepeatPartitionIterator","text":"RepeatPartitionIterator\nRepeatPartitionIterator(base, nrep)\n\nIteratates over iterators of a subset of size nrep elements in base.\n\nGenerally useful for training all models in a population with the same data in each evolution epoch.\n\nTailored for situations where iterating over models is more expensive than iterating over data, for  example if candidates are stored in host RAM or on disk and needs to be transferred to the GPU for training.\n\nExample training loop:\n\n\nfor partiter in iter\n\n    for model in population\n        train!(model, partiter)\n    end\n\n    evolvepopulation(population)\nend\n\n\n\n\n\n","category":"type"},{"location":"reference/iterators/#NaiveGAflux.SeedIterator","page":"Iterators","title":"NaiveGAflux.SeedIterator","text":"SeedIterator\nSeedIterator(base; rng=rng_default, seed=rand(rng, UInt32))\n\nIterator which has the random seed of an AbstractRNG as state.\n\nCalls Random.seed!(rng, seed) every iteration so that wrapped iterators which depend on rng will produce the same sequence.\n\nUseful in conjunction with RepeatPartitionIterator and BatchIterator and/or random data augmentation so that all candidates in a generation are trained with identical data.\n\n\n\n\n\n","category":"type"},{"location":"reference/iterators/#NaiveGAflux.GpuIterator","page":"Iterators","title":"NaiveGAflux.GpuIterator","text":"GpuIterator(itr)\n\nReturn an iterator which sends values from itr to the GPU.\n\n\n\n\n\n","category":"function"},{"location":"reference/iterators/#NaiveGAflux.BatchIterator","page":"Iterators","title":"NaiveGAflux.BatchIterator","text":"BatchIterator{R, D}\nBatchIterator(data, batchsize; shuffle)\n\nReturn an iterator which iterates batchsize samples along the last dimension of data  or all elements of data if data is a Tuple (e.g (features, labels)).\n\nWill shuffle examples if shuffle is true or an AbstractRNG. Shuffling will be  different each time iteration starts (subject to implementation of shuffle(rng,...)).  \n\n\n\n\n\n","category":"type"},{"location":"reference/iterators/#NaiveGAflux.TimedIterator","page":"Iterators","title":"NaiveGAflux.TimedIterator","text":"TimedIterator{F,A,I}\nTimedIterator(;timelimit, patience, timeoutaction, accumulate_timeouts, base)\n\nMeasures time between iterations and calls timeoutaction() if this time is longer than timelimit patience number of times.\n\nIntended use is to quickly abort training of models which take very long time to train, typically also assigning them a very low fitness in case of a timeout.\n\nBy default, calling timeoutaction() will not stop the iteration as this would break otherwise convenient functions like length, collect and map. Let timeoutaction() return TimedIteratorStop to stop iteration.\n\nIf accumulate_timeouts is false then counting will reset when time between iterations is shorter than timelimit, otherwise it will not.\n\n\n\n\n\n","category":"type"},{"location":"reference/iterators/#NaiveGAflux.StatefulGenerationIter","page":"Iterators","title":"NaiveGAflux.StatefulGenerationIter","text":"StatefulGenerationIter{T, VS}\n\nUses a RepeatPartitionIterator to ensure that the same iterator is returned for the same generation number.\n\n\n\n\n\n","category":"type"},{"location":"#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"NaiveGAflux is a toolbox for doing neural architecture search for Flux models using genetic algorithms.  It is primarily designed for searching by making modifications to well performing models. This is typically  done in a train-validate-select-evolve loop where the validation metric serves as the fitness in selection.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"There is however absolutely no enforcement of this structure and the parts are designed to work standalone and in a composable manner to support a wide variety of search strategies.","category":"page"},{"location":"#Readers-Guideline","page":"Introduction","title":"Readers Guideline","text":"","category":"section"},{"location":"","page":"Introduction","title":"Introduction","text":"The Quick Tutorial serves as a starting point to get an idea of the syntax and type of capabilities of NaiveGAflux.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"NaiveGAflux comes bundled with a neural architecture search application called AutoFlux which glues most of NaiveGAfluxs components together.  This is a good next read if you are interested in quickly getting started with model search using a standard train-validate-select-evolve loop.  It is however a bit disconnected from NaiveGAflux and many readers will find it better to just continue to the next sections.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"There is a short set of examples for each main component types. Each component is designed to work well in isolation and examples are largely  self-contained, allowing you to pick and choose the ones you like when building an own application.","category":"page"},{"location":"","page":"Introduction","title":"Introduction","text":"Search Spaces\nMutation Operations\nCrossover Operations\nFitness Functions\nCandidate Utilities\nEvolution Strategies\nIterators","category":"page"},{"location":"reference/utils/#Misc.-Utilities","page":"Misc. Utilities","title":"Misc. Utilities","text":"","category":"section"},{"location":"reference/utils/","page":"Misc. Utilities","title":"Misc. Utilities","text":"MutationShield\nApplyIf\nPersistentArray\npersist\nShieldedOpt","category":"page"},{"location":"reference/utils/#NaiveGAflux.MutationShield","page":"Misc. Utilities","title":"NaiveGAflux.MutationShield","text":"MutationShield <: DecoratingTrait\nMutationShield(t, allowed...)\n\nShields its associated vertex from being selected for mutation.\n\nAny types in allowed will be allowed to mutate the vertex if supplied when calling allow_mutation.\n\nNote that vertex might still be modified if an adjacent vertex is mutated in a way which propagates to a shielded vertex.\n\n\n\n\n\n","category":"type"},{"location":"reference/utils/#NaiveGAflux.ApplyIf","page":"Misc. Utilities","title":"NaiveGAflux.ApplyIf","text":"ApplyIf <: DecoratingTrait\nApplyIf(predicate::Function, apply::Function, base::MutationTrait)\n\nEnables calling apply(v) for an AbstractVertex v which has this trait if 'predicate(v) == true'.\n\nMotivating use case is to have a way to remove vertices which have ended up as noops, e.g. element wise and concatenation vertices with a single input or identity activation functions.\n\n\n\n\n\n","category":"type"},{"location":"reference/utils/#NaiveGAflux.PersistentArray","page":"Misc. Utilities","title":"NaiveGAflux.PersistentArray","text":"PersistentArray{T, N} <: AbstractArray{T, N}\nPersistentArray(savedir::String, nr::Integer, generator;suffix=\".jls\")\nPersistentArray(savedir::String, suffix::String, data::Array)\n\nSimple persistent array. Can be created from serialized data and can be asked to persist its elements using persist.\n\nNote that once initialized, the array is not backed by the serialized data. Adding/deleting files is not reflected in data and vice versa.\n\n\n\n\n\n","category":"type"},{"location":"reference/utils/#NaiveGAflux.persist","page":"Misc. Utilities","title":"NaiveGAflux.persist","text":"persist(a::PersistentArray)\n\nSerializes the elements of a, one file per element.\n\n\n\n\n\n","category":"function"},{"location":"reference/utils/#NaiveGAflux.ShieldedOpt","page":"Misc. Utilities","title":"NaiveGAflux.ShieldedOpt","text":"ShieldedOpt{O} <: Flux.Optimise.AbstractOptimiser \nShieldedOpt(o)\n\nShields o from mutation by OptimizerMutation.\n\n\n\n\n\n","category":"type"}]
}
